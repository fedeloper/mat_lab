{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIGuQbmAl3-q"
   },
   "source": [
    "# Readme: how to handle our Sentinel-1 ASC-DESC dataset\n",
    "\n",
    "###What you have: \n",
    "A list of big geotiff file (.tif) Pairs. Each image in the pair should roughly correspond to the same area as the other. Each geotiff can by read using rasterio or gdal, as you can see in the notebook.\n",
    "\n",
    "###What you should do: \n",
    "create single datapoints to train/test your models.\n",
    "\n",
    "###How to do it: \n",
    "For each big pair, get a datapoint by cropping a random patch from one side (this acts as the \"query\" patch, the one you want to look for) and cropping a patch around the same coordinates from the other side (this acts as the \"search\" patch, the one to want to search in). Add distortions: search patch has to be taken with a random offset around query patch (perhaps random but normally distributed around offset 0, which means query patch at the centre). Also add a bit of random scale and rotation.Try finding a 1km^2 query patch inside a 4km^2 search patch. \n",
    "\n",
    "###Some WARNINGS (not too sure about them)\n",
    "\n",
    "Warning: do not include every correspondence in the ground truth pixel correspondence list! you should only insert meaningful correspondences such as harris corners.\n",
    "\n",
    "Warning: maybe discard a candidate query altogether if it's not feature-rich enough. You can do this using pixel histograms (has to have more than n peaks -> use scikit learn), or maybe entropy. for example, if every pixel is around e.g. 150, this means that everything is gray and unmatchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (1.3.5.post1)\r\n",
      "Requirement already satisfied: numpy>=1.18 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.23.4)\r\n",
      "Requirement already satisfied: certifi in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2022.12.7)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: attrs in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (22.2.0)\r\n",
      "Requirement already satisfied: setuptools in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (65.6.3)\r\n",
      "Requirement already satisfied: click-plugins in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.1.1)\r\n",
      "Requirement already satisfied: affine in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2.4.0)\r\n",
      "Requirement already satisfied: click>=4.0 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (8.1.3)\r\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\r\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from pymagsac import pymagsac\n",
    "from scipy.ndimage import uniform_filter, variance\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "from src.loftr import LoFTR\n",
    "from src.loftr.utils.cvpr_ds_config import default_cfg\n",
    "from src.utils.plotting import make_matching_figure\n",
    "\n",
    "from rasterio.crs import CRS\n",
    "from rasterio import transform as tform\n",
    "\n",
    "! pip install rasterio\n",
    "import rasterio as rio\n",
    "from rasterio import warp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Need this to plot in HD\n",
    "# This takes up a lot of memory!\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "if 'model_TransSAR' not in locals():\n",
    "    model_TransSAR = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "def get_correspondence(i, j, llh_array, transform, crs):\n",
    "    ''' Given row and column in SLC image, get corresponding row and column in rasterio dataset.\n",
    "    @param i: row in slc.\n",
    "    @param j: column in slc.\n",
    "    @param llh_array: the llh as a dictionary of numpy arrays (one per lat, long, height).\n",
    "    @param grd_ds: the grd as a rasterio dataset.\n",
    "    @param transform: the geotransform of the rasterio dataset.\n",
    "    @param crs: the crs of the rasterio dataset.\n",
    "    @return i_ref: row in grd.\n",
    "    @return j_ref: column in grd.\n",
    "    '''\n",
    "    i = round(i)\n",
    "    j = round(j)\n",
    "    lat = llh_array[f'llh.lat'][i][j]\n",
    "    lon = llh_array[f'llh.long'][i][j]\n",
    "    # Convert the EPSG:4326 coordinate to the CRS of the raster\n",
    "    X, Y = warp.transform(crs, CRS.from_string(\"EPSG:4326\"), [lon], [lat])\n",
    "    # Calculate the corresponding pixel coordinate\n",
    "    # i_ref, j_ref = dataset_ref.index(X, Y)\n",
    "    j_ref, i_ref = ~transform * (X[0], Y[0])\n",
    "    i_ref = round(i_ref)\n",
    "    j_ref = round(j_ref)\n",
    "    return i_ref, j_ref\n",
    "\n",
    "def get_datapoint(ref_data, query_data):\n",
    "    ''' TODO: Call this method on a pair of rasterio datasets. It will generate a random datapoint consisting\n",
    "        of a smaller SAR patch from the query dataset, and a bigger SAR patch from the reference dataset.\n",
    "        The search patch contains the area of the smaller patch, with a random offset.\n",
    "    '''\n",
    "    datapoint = None\n",
    "    return datapoint\n",
    "\n",
    "\n",
    "def is_good_patch(patch):\n",
    "    ''' TODO: Checks if the random query patch is sufficiently texture-rich to be used to train/test the matching model.\n",
    "        If the patch is too plain (e.g. sea or desert), returns False. This function should also be used at test time:\n",
    "        if a sensor image is too plain, there's no need to match it.\n",
    "        At test time, something similar should also be done on the reference side.\n",
    "    '''\n",
    "    good = None\n",
    "    return good\n",
    "\n",
    "\n",
    "def get_keypoints(patch):\n",
    "    ''' TODO: Use something like harris corner detection to get the list of ground truth correspondences.\n",
    "        In fact, you should not train on each pixel corresp, but you should select only meaningful corresp!\n",
    "        Harris peaks might be just strong speckle noise, but if you take strong ones you should be fine.\n",
    "    '''\n",
    "    keypoints = None\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    ''' Normalize by clipping to 99th percentile and convert to uint8.\n",
    "        This clips strong speckle outliers and optimizes the brightness range\n",
    "    '''\n",
    "    p1 = np.nanpercentile(img, 99)\n",
    "    img = img.clip(0, p1)\n",
    "    img = (img - np.nanmin(img)) / (np.nanmax(img) - np.nanmin(img)) * 255\n",
    "    img = img.astype(np.uint8, copy=True)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "paths = [\n",
    "    './data/paired_sentinel/Sentinel1-AD Dataset- Lat-0.015502064951149919Lon41.3552557262833/S1A_IW_GRDH_1SDV_20220808T060138_20220808T060203_044457_054E18_B16D.tif',\n",
    "    './data/paired_sentinel/Sentinel1-AD Dataset- Lat-0.015502064951149919Lon41.3552557262833/S1A_IW_GRDH_1SDV_20220814T175523_20220814T175548_044552_055140_2AEA.tif']\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def get_sample(ph, search_window, patch_size, margin=80, random_seed=1, verbose=True,\n",
    "               random_rotation=0.03, random_zoom=0.03,inner_margin=30):\n",
    "    '''\n",
    "          1-Reads the first band of the TIFF files using the rio library and normalizes the image data.\n",
    "          2-Selects a random search window and patch location within the image using random number generators.\n",
    "          3-Calls the get_correspondence function on the selected locations to find the corresponding locations in the second image.\n",
    "          4-Converts the grayscale images to RGB format using OpenCV.\n",
    "          5-Creates centered patches from the RGB images by zero-padding the images and copying a portion of the original images to the patches.\n",
    "          6-Draws rectangles around the search window and patch in both images.\n",
    "          7-Saves the patch and search window as JPEG files.\n",
    "          8-Returns the processed RGB images, the points of the search window and patch, and the original rio datasets.\n",
    "\n",
    "    '''\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    img1 = cv2.imread(p1, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(p2, cv2.IMREAD_GRAYSCALE)\n",
    "    img1 = cv2.resize(img1, (img1.shape[1]//8*8, img1.shape[0]//8*8))  # input size shuold be divisible by 8\n",
    "    img2 = cv2.resize(img2, (img2.shape[1]//8*8, img2.shape[0]//8*8))\n",
    "\n",
    "\n",
    "    img1 = np.swapaxes(img1, 0, 1)\n",
    "    img2 = np.swapaxes(img2, 0, 1)\n",
    "\n",
    "    search_window_w, search_window_h = search_window\n",
    "    patch_size_w, patch_size_h = patch_size\n",
    "\n",
    "    if img1.shape[0] - search_window_w - margin * 2 < 0 or img1.shape[1] - search_window_h - margin * 2 < 0:\n",
    "        print(\"margin + search windows is too big for the image:\", margin, \"*2 +\", (search_window_w, search_window_h),\n",
    "              \">\", img1.shape)\n",
    "        return None, None, None, None, None, None, None\n",
    "    lu = (margin + random.randint(0, img1.shape[0] - search_window_w - margin * 2),\n",
    "          margin + random.randint(0, img1.shape[1] - search_window_h - margin * 2))\n",
    "    rd = (lu[0] + search_window_w ,  lu[1] + search_window_h)\n",
    "    lu_patch = (lu[0] + inner_margin+ random.randint(0, search_window_w - patch_size_w- 2* inner_margin),\n",
    "                lu[1] + inner_margin + random.randint(0, search_window_h - patch_size_h- 2* inner_margin))\n",
    "    rd_patch = (lu_patch[0] + search_window_w ,  lu_patch[1] + search_window_h)\n",
    "\n",
    "    points_patch = lu_patch\n",
    "    points = lu\n",
    "    #print(points,\"points\",img1.shape)\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    # load llh\n",
    "    with open(hhl_path, 'rb') as f:\n",
    "        query_lat = np.load(f)\n",
    "        query_long = np.load(f)\n",
    "    llh = {}\n",
    "    llh[f'llh.lat'] = query_lat\n",
    "    llh[f'llh.long'] = query_long\n",
    "\n",
    "    # load geotransform\n",
    "    with open(crs_path, 'rb') as f:\n",
    "        trans = np.load(f)\n",
    "        trans = tform.Affine(*trans.flatten()[:6])\n",
    "        crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "\n",
    "    points_ref = get_correspondence(lu[0], lu[1], llh, trans, crs)\n",
    "    points_patch_ref = get_correspondence(lu_patch[0],lu_patch[1] , llh, trans, crs)\n",
    "\n",
    "    rgb_img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "    rgb_img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    patch_source = np.zeros((search_window_w, search_window_h), dtype=np.uint8)\n",
    "\n",
    "    patch_source[int(search_window_w / 2 - patch_size_w / 2):int(search_window_w / 2 + patch_size_w / 2),\n",
    "    int(search_window_h / 2 - patch_size_h / 2):int(search_window_h / 2 + patch_size_h / 2)] = img1[points_patch[0]:\n",
    "                                                                                                    points_patch[\n",
    "                                                                                                        0] + patch_size_w,\n",
    "                                                                                               points_patch[1]:\n",
    "                                                                                               points_patch[\n",
    "                                                                                                   1] + patch_size_h]\n",
    "\n",
    "    patch_dest = np.zeros((search_window_w, search_window_h), dtype=np.uint8)\n",
    "    patch_dest[int(search_window_w / 2 - patch_size_w / 2):int(search_window_w / 2 + patch_size_w / 2),\n",
    "    int(search_window_h / 2 - patch_size_h / 2):int(search_window_h / 2 + patch_size_h / 2)] = img2[points_patch_ref[0]:\n",
    "                                                                                                    points_patch_ref[\n",
    "                                                                                                        0] + patch_size_w,\n",
    "                                                                                               points_patch_ref[1]:\n",
    "                                                                                               points_patch_ref[\n",
    "                                                                                                   1] + patch_size_h]\n",
    "\n",
    "    search_window_source = img1[points[0]:points[0] + search_window_w, points[1]:points[1] + search_window_h]\n",
    "    search_window_dest = img2[points_ref[0]:points_ref[0] + search_window_w,\n",
    "                         points_ref[1]: points_ref[1] + search_window_h]\n",
    "\n",
    "\n",
    "\n",
    "    #draw searching windows\n",
    "\n",
    "    rgb_img1 = cv2.rectangle(rgb_img1, tuple(reversed(points)),\n",
    "                             (points[1] + search_window_h, points[0] + search_window_w), (0, 0, 255), 2)\n",
    "    rgb_img1 = cv2.rectangle(rgb_img1, tuple(reversed(points_patch)),\n",
    "                             (points_patch[1] + patch_size_h, points_patch[0] + patch_size_w), (255, 0, 0), 2)\n",
    "\n",
    "    #draw patch windows\n",
    "    rgb_img2 = cv2.rectangle(rgb_img2, tuple(reversed(points_ref)),\n",
    "                             (points_ref[1] + search_window_h, points_ref[0] + search_window_w), (0, 0, 255), 2)\n",
    "    rgb_img2 = cv2.rectangle(rgb_img2, tuple(reversed(points_patch_ref)),\n",
    "                             (points_patch_ref[1] + patch_size_h, points_patch_ref[0] + patch_size_w), (255, 0, 0), 2)\n",
    "\n",
    "    #print(rgb_img1.shape,search_window_source.shape)\n",
    "\n",
    "    rgb_img1 = np.swapaxes(rgb_img1, 0, 1)\n",
    "    rgb_img2 = np.swapaxes(rgb_img2, 0, 1)\n",
    "    search_window_source = np.swapaxes(search_window_source, 0, 1)\n",
    "    patch_source = np.swapaxes(patch_source, 0, 1)\n",
    "    search_window_dest = np.swapaxes(search_window_dest, 0, 1)\n",
    "    patch_dest = np.swapaxes(patch_dest, 0, 1)\n",
    "    if verbose:\n",
    "        fig, axes = plt.subplots(2, 3)\n",
    "        axes[0, 0].set_title('source image')\n",
    "        print(rgb_img1.shape)\n",
    "        axes[0, 0].imshow(PIL.ImageOps.invert(Image.fromarray(rgb_img1)))\n",
    "\n",
    "        axes[0, 1].set_title('search window source')\n",
    "        axes[0, 1].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(search_window_source, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[0, 2].set_title('patch source')\n",
    "        axes[0, 2].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(patch_source, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[1, 0].set_title('dest image')\n",
    "        axes[1, 0].imshow(PIL.ImageOps.invert(Image.fromarray(rgb_img2)))\n",
    "\n",
    "        axes[1, 1].set_title('search window dest')\n",
    "        axes[1, 1].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(search_window_dest, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[1, 2].set_title('patch dest')\n",
    "        axes[1, 2].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(patch_dest, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        plt.show()\n",
    "    rgb_img1 = np.swapaxes(rgb_img1, 0, 1)\n",
    "    rgb_img2 = np.swapaxes(rgb_img2, 0, 1)\n",
    "    patch_dest = np.swapaxes(patch_dest, 0, 1)\n",
    "    search_window_source = np.swapaxes(search_window_source, 0, 1)\n",
    "\n",
    "    return patch_dest,search_window_source,rgb_img1, rgb_img2, points, points_patch_ref, points_patch\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # init a costum parser which will be added into pl.Trainer parser\n",
    "    # check documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        'data_cfg_path', type=str, default=\".\", help='data config path')\n",
    "    parser.add_argument(\n",
    "        '--ckpt_path', type=str, default=\"weights/indoor_large-SEA.ckpt\", help='path to the checkpoint')\n",
    "    parser.add_argument(\n",
    "        '--dump_dir', type=str, default=None, help=\"if set, the matching results will be dump to dump_dir\")\n",
    "    parser.add_argument(\n",
    "        '--profiler_name', type=str, default='inference', help='options: [inference, pytorch], or leave it unset')\n",
    "    parser.add_argument(\n",
    "        '--batch_size', type=int, default=1, help='batch_size per gpu')\n",
    "    parser.add_argument(\n",
    "        '--num_workers', type=int, default=2)\n",
    "    parser.add_argument(\n",
    "        '--thr', type=float, default=None, help='modify the coarse-level matching threshold.')\n",
    "\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_matcher(image_type, unlock=False):\n",
    "    matcher = LoFTR(config=default_cfg)\n",
    "    if image_type == 'indoor':\n",
    "      matcher.load_state_dict(torch.load(\"weights/indoor_ds.ckpt\")['state_dict'])\n",
    "    elif image_type == 'outdoor':\n",
    "      matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "    #model = PL_LoFTR(config, pretrained_ckpt=args.ckpt_path, profiler=profiler)\n",
    "    return matcher.eval().cuda()\n",
    "from skimage.measure import ransac\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(mkpts0_r, mkpts1_r, points, points_patch,points_patch_ref,ph, searching_window_w, searching_window_h,\n",
    "                patch_w, patch_h):\n",
    "\n",
    "\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    # load llh\n",
    "    with open(hhl_path, 'rb') as f:\n",
    "        query_lat = np.load(f)\n",
    "        query_long = np.load(f)\n",
    "    llh = {}\n",
    "    llh[f'llh.lat'] = query_lat\n",
    "    llh[f'llh.long'] = query_long\n",
    "\n",
    "    # load geotransform\n",
    "    with open(crs_path, 'rb') as f:\n",
    "        trans = np.load(f)\n",
    "        trans = tform.Affine(*trans.flatten()[:6])\n",
    "        crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "\n",
    "    # Extract x and y coordinates from mkpts0\n",
    "    x0, y0 = zip(*mkpts0_r)\n",
    "\n",
    "    # Apply translation to the coordinates\n",
    "    rmse = 0\n",
    "    for idx in range(len(mkpts0_r)):\n",
    "\n",
    "\n",
    "        i_slc, j_slc = round(mkpts1_r[idx,1]), round(mkpts1_r[idx,0]) # QUERY - UAV\n",
    "\n",
    "        i_grd, j_grd = round(mkpts0_r[idx,1]), round(mkpts0_r[idx,0]) # SEARCH - SAT\n",
    "        i_grd += points[0]\n",
    "        j_grd  += points[1]\n",
    "\n",
    "        j_slc = j_slc - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1]\n",
    "        i_slc = i_slc - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0]\n",
    "        # Given point in SLC, get correspondence in GRD\n",
    "        j_ref, i_ref = get_correspondence(j_slc, i_slc, llh, trans, crs)\n",
    "\n",
    "\n",
    "        rmse += (i_grd - i_ref)**2 + (j_grd - j_ref)**2\n",
    "    # Convert the translated coordinates back to tuples\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize the errors by the number of keypoints\n",
    "    num_kpts = len(mkpts1_r)\n",
    "    rmse = (rmse / num_kpts) ** (\n",
    "            1 / 2)  # like in \"A Transformer-Based Coarse-to-Fine Wide-Swath SAR Image Registration Method under Weak Texture Conditions\"\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def cornerness_friendly(gray, points, inliers,random_select=False):\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 15)\n",
    "\n",
    "    corners = np.int0(corners)\n",
    "    harris_near = np.zeros((points.shape[0])) + 500\n",
    "\n",
    "    for match in range(len(points)):\n",
    "        if inliers[match]:\n",
    "            arr = [abs(points[match][0] - corner.ravel()[0]) + abs(points[match][1] - corner.ravel()[1]) for corner in\n",
    "                   corners]\n",
    "            harris_near[match] = min(arr)\n",
    "    result= harris_near.argsort()\n",
    "    if random_select:\n",
    "      random.shuffle(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def postproces_and_metric(conf, mkpts0, mkpts1, img0, ph, points, points_patch,points_patch_ref, searching_window_w,\n",
    "                          searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2, mconf, threshold_inliers, random_select,\n",
    "                          save_pdf=True):\n",
    "    if conf['residual_threshold'] >= 0:\n",
    "\n",
    "        import time\n",
    "\n",
    "        # get the start time\n",
    "        st = time.time()\n",
    "        order = (mconf).argsort()\n",
    "        mkpts0 = mkpts0[order]\n",
    "        mkpts1 = mkpts1[order]\n",
    "        mconf = mconf[order]\n",
    "\n",
    "        probabilities = mconf+ min(mconf)\n",
    "        probabilities  /= max(probabilities )\n",
    "\n",
    "        correspondences = np.float32([ np.concatenate(( mkpts0[m] , mkpts1[m] )) for m in range(len(mkpts0))]).reshape(-1,4)\n",
    "        H, inliers = pymagsac.findHomography(\n",
    "        np.ascontiguousarray(correspondences),\n",
    "        searching_window_w, searching_window_h, searching_window_w, searching_window_h,\n",
    "        probabilities = probabilities ,\n",
    "        sampler = 4,\n",
    "        #conf = 0.,\n",
    "        use_magsac_plus_plus = False,\n",
    "            min_iters = conf['max_trials'],\n",
    "        max_iters=conf['max_trials'],\n",
    "\n",
    "        sigma_th = float(conf['residual_threshold']))\n",
    "        et = time.time()\n",
    "\n",
    "        # get the execution time\n",
    "        elapsed_time = et - st\n",
    "        print('Magsac Execution time:', elapsed_time, 'seconds inliers:', np.sum(inliers))\n",
    "\n",
    "    else:\n",
    "        inliers = np.zeros_like(range(mkpts0.shape[0]))\n",
    "        inliers[:] = True\n",
    "\n",
    "\n",
    "    threshold_inliers = threshold_inliers if threshold_inliers >= 0 else np.sum(inliers)\n",
    "    n_inliers = np.sum(inliers)\n",
    "\n",
    "    if inliers is None or n_inliers is None or n_inliers == 0 or (n_inliers < threshold_inliers) :\n",
    "        conf.update({'rmse': -1, 'inliers': 0 if n_inliers is None else n_inliers})\n",
    "    else:\n",
    "        gray = np.array(img0.cpu()).squeeze()\n",
    "        new_order = cornerness_friendly(gray, mkpts0, inliers,random_select)\n",
    "\n",
    "\n",
    "        inliers = inliers[new_order]\n",
    "        print(mkpts0.shape,mkpts0[new_order][inliers][:threshold_inliers].shape)\n",
    "\n",
    "        rmse = get_metrics(mkpts0[new_order][inliers][:threshold_inliers], mkpts1[new_order][inliers][:threshold_inliers], points,\n",
    "                           points_patch,points_patch_ref, ph,\n",
    "                           searching_window_w, searching_window_h, patch_w, patch_h)\n",
    "        conf.update({'rmse': rmse, 'inliers': n_inliers})\n",
    "        p1,crs_path,p2,hhl_path = ph\n",
    "        # load llh\n",
    "        with open(hhl_path, 'rb') as f:\n",
    "            query_lat = np.load(f)\n",
    "            query_long = np.load(f)\n",
    "        llh = {}\n",
    "        llh[f'llh.lat'] = query_lat\n",
    "        llh[f'llh.long'] = query_long\n",
    "\n",
    "        # load geotransform\n",
    "        with open(crs_path, 'rb') as f:\n",
    "            trans = np.load(f)\n",
    "            trans = tform.Affine(*trans.flatten()[:6])\n",
    "            crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "        if save_pdf:\n",
    "            color = cm.jet(mconf[new_order][inliers][:threshold_inliers], alpha=0.7)\n",
    "            abs_m0 = np.array([(x + points[1], y + points[0]) for x, y in mkpts0[new_order][inliers][:threshold_inliers]])\n",
    "            abs_m1 = np.array([(x - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1],\n",
    "                                y - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0]) for x, y in\n",
    "                               mkpts1[new_order][inliers][:threshold_inliers]])\n",
    "            #abs_m0 = np.array([(get_correspondence(abs_m1[0][0],abs_m1[0][1],llh, trans, crs))])\n",
    "            text = [\n",
    "                str(conf),\n",
    "                'Matches: {}'.format(len(mkpts0[new_order][inliers][:threshold_inliers])),\n",
    "                \"x - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1]\",\n",
    "                \"x - ((\"+str(searching_window_h)+str(\"/2)-\") + str(patch_h) + str(\" / 2)) + \") + str(points_patch_ref[1]),\n",
    "                \"y - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0])\",\n",
    "                \"y - ((\"+str(searching_window_w)+str(\"/2)-\") + str(patch_w) + str(\" / 2)) + \") + str(points_patch_ref[0]),\n",
    "            ]\n",
    "\n",
    "            if conf['residual_threshold'] <= 0.5:\n",
    "\n",
    "                if verbose:\n",
    "                   fig = make_matching_figure(rgb_img1, rgb_img2, abs_m0, abs_m1, color, abs_m0[:1], abs_m1,\n",
    "                                           text)\n",
    "            make_matching_figure(rgb_img1, rgb_img2, abs_m0, abs_m1, color, abs_m0, abs_m1, text,\n",
    "                                 path=\"magsacpp\"+str(conf['residual_threshold']) +\"_rmse_\"+str(rmse)+\"_inliers_\" + str(n_inliers) +\".pdf\")\n",
    "    return conf\n",
    "\n",
    "\n",
    "def predict_and_print(ph,rgb_img1, rgb_img2, matcher, img0_raw, img1_raw, points, points_patch,points_patch_ref,\n",
    "                      searching_window_w, searching_window_h, patch_w, patch_h, configs_ransac ,threshold_inliers,random_select =False):\n",
    "    '''\n",
    "        This code performs an image matching task with the given matcher, which takes two raw images and outputs corresponding features. The code first resizes the two raw images to (640, 480) and converts them to torch tensors, normalizing them by dividing each pixel by 255. The two images are then passed to the matcher to get feature matches and confidence scores.\n",
    "        The code then computes two weighted average points based on the matches, one weighted by the confidence score and the other by a uniform weight. If the number of matches is greater than 0, the code returns the weighted average points and prints them as figures if verbose is set to True. The output figures are saved as \"LoFTR-colab-demo.pdf\".\n",
    "I       f there are no matches, the code returns None, None, None, None.\n",
    "'''\n",
    "\n",
    "    img0 = torch.from_numpy(img0_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "    img1 = torch.from_numpy(img1_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "\n",
    "    batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "    # Inference with LoFTR and get prediction\n",
    "    with torch.no_grad():\n",
    "\n",
    "        torch.cuda.reset_peak_memory_stats(device=\"cuda\")\n",
    "        matcher(batch)\n",
    "        print(\"max memory allocated cuda\", torch.cuda.max_memory_allocated(device=\"cuda\"))\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "\n",
    "    if mkpts0.shape[0] > 0:\n",
    "        return [postproces_and_metric(conf, mkpts0, mkpts1, img0, ph, points, points_patch,points_patch_ref,\n",
    "                                           searching_window_w, searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2,\n",
    "                                           mconf, threshold_inliers,random_select) for conf in configs_ransac]\n",
    "\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "\n",
    "loaddirec = \"model.pth\"\n",
    "save_path = \"./\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "'''\n",
    " It takes two images as input, performs image denoising, and then uses a matcher to find the similarity between a patch from the first image and the second image.\n",
    "\n",
    "The code uses a loop to run the processing for 50 times, for each iteration:\n",
    "\n",
    "It calls the function get_sample to get the images, points, and datasets.\n",
    "It denoises the raw images using 3 denoising methods (mean, bilateral, and lee_enhanced). If the denoising didn't produce a result, the code skips to the next iteration.\n",
    "The code calls the function predict_and_print to get the result of the matcher and to find the similarity between the patch and the search window.\n",
    "The code uses the result of the matcher to calculate the error in meters between the predicted position and the real position.\n",
    "The code draws circles on the original full map to show the predicted and real positions.\n",
    "The code displays the original full map if verbose is set to True.\n",
    "The code accumulates the error for each iteration and prints the final result, which includes the number of successful predictions and the mean error in meters.\n",
    "'''\n",
    "\n",
    "\n",
    "def lee_filter(img, size):\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img ** 2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean ** 2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output\n",
    "\n",
    "\n",
    "def do_test(matcher_in, ph, size_search=(640, 480), size_patch=(int(180 * 1.333333), int(180)),threshold_inliers=5,\n",
    "            configs_ransac=None, verbose=True,random_select=False):\n",
    "\n",
    "    patch_dest,search_window_source, rgb_img1, rgb_img2, points, points_patch_ref, points_patch = get_sample(ph,\n",
    "                                                                                                size_search, size_patch,\n",
    "                                                                                                verbose=verbose)\n",
    "    if rgb_img1 is None:\n",
    "        return None\n",
    "\n",
    "    import skimage.measure\n",
    "\n",
    "    results = predict_and_print(ph,rgb_img1, rgb_img2, matcher_in, search_window_source, patch_dest, points, points_patch,points_patch_ref,\n",
    "                                 size_search[0], size_search[1], size_patch[0], size_patch[1]\n",
    "                                , configs_ransac,threshold_inliers,random_select\n",
    "                               )\n",
    "\n",
    "    entropy = skimage.measure.shannon_entropy(patch_dest)\n",
    "\n",
    "    return results, entropy\n",
    "\n",
    "\n",
    "def get_list():\n",
    "    path_of_the_directory = './data/UAVSAR/'\n",
    "    paths = []\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        f = os.path.join(path_of_the_directory, filename)\n",
    "        if len(os.listdir(f)) > 3:\n",
    "            if not os.path.isfile(f):\n",
    "                lst = sorted([os.path.abspath(os.path.join(f, p)) for p in os.listdir(f)])\n",
    "                lst = [item for item in lst if \"az_rg\" not in item]\n",
    "                paths.append(lst)\n",
    "\n",
    "    return paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(560, 2) (25, 2)\n",
      "Magsac Execution time: 0.0017940998077392578 seconds inliers: 25\n",
      "(560, 2) (25, 2)\n",
      "Magsac Execution time: 0.0023157596588134766 seconds inliers: 25\n",
      "(560, 2) (25, 2)\n",
      "Magsac Execution time: 0.002171039581298828 seconds inliers: 25\n",
      "(560, 2) (25, 2)\n",
      "Magsac Execution time: 0.0022072792053222656 seconds inliers: 25\n",
      "(560, 2) (25, 2)\n",
      "Magsac Execution time: 0.0024979114532470703 seconds inliers: 25\n",
      "(560, 2) (25, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 18.0, 'inliers': 560}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 47.11517802152508, 'inliers': 25}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': 47.11517802152508, 'inliers': 25}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': 47.11517802152508, 'inliers': 25}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': 47.11517802152508, 'inliers': 25}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': 47.11517802152508, 'inliers': 25}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(565, 2) (25, 2)\n",
      "Magsac Execution time: 0.0019252300262451172 seconds inliers: 18\n",
      "Magsac Execution time: 0.002662181854248047 seconds inliers: 18\n",
      "Magsac Execution time: 0.0019004344940185547 seconds inliers: 18\n",
      "Magsac Execution time: 0.002054452896118164 seconds inliers: 18\n",
      "Magsac Execution time: 0.0022115707397460938 seconds inliers: 18\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 6.082762530298219, 'inliers': 565}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 18}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(525, 2) (25, 2)\n",
      "Magsac Execution time: 0.0012774467468261719 seconds inliers: 13\n",
      "Magsac Execution time: 0.0015211105346679688 seconds inliers: 13\n",
      "Magsac Execution time: 0.0013630390167236328 seconds inliers: 13\n",
      "Magsac Execution time: 0.0014338493347167969 seconds inliers: 13\n",
      "Magsac Execution time: 0.0016140937805175781 seconds inliers: 13\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 316.76016163652906, 'inliers': 525}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 13}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(542, 2) (25, 2)\n",
      "Magsac Execution time: 0.0016095638275146484 seconds inliers: 8\n",
      "Magsac Execution time: 0.002295255661010742 seconds inliers: 8\n",
      "Magsac Execution time: 0.001752614974975586 seconds inliers: 8\n",
      "Magsac Execution time: 0.0017457008361816406 seconds inliers: 8\n",
      "Magsac Execution time: 0.0019068717956542969 seconds inliers: 8\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 115.0173899895142, 'inliers': 542}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 8}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(557, 2) (25, 2)\n",
      "Magsac Execution time: 0.0012907981872558594 seconds inliers: 8\n",
      "Magsac Execution time: 0.0014824867248535156 seconds inliers: 7\n",
      "Magsac Execution time: 0.0013413429260253906 seconds inliers: 7\n",
      "Magsac Execution time: 0.0014595985412597656 seconds inliers: 7\n",
      "Magsac Execution time: 0.0016410350799560547 seconds inliers: 7\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 314.8714023216462, 'inliers': 557}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 7}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(483, 2) (25, 2)\n",
      "Magsac Execution time: 0.0012888908386230469 seconds inliers: 11\n",
      "Magsac Execution time: 0.0018329620361328125 seconds inliers: 11\n",
      "Magsac Execution time: 0.0013811588287353516 seconds inliers: 11\n",
      "Magsac Execution time: 0.001531362533569336 seconds inliers: 11\n",
      "Magsac Execution time: 0.0017011165618896484 seconds inliers: 11\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 247.34186867572583, 'inliers': 483}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 11}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(593, 2) (25, 2)\n",
      "Magsac Execution time: 0.00228118896484375 seconds inliers: 14\n",
      "Magsac Execution time: 0.002840280532836914 seconds inliers: 14\n",
      "Magsac Execution time: 0.002603769302368164 seconds inliers: 14\n",
      "Magsac Execution time: 0.002745389938354492 seconds inliers: 14\n",
      "Magsac Execution time: 0.002877473831176758 seconds inliers: 14\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 171.39719951037708, 'inliers': 593}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 14}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 300, 'rmse': -1, 'inliers': 14}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 700, 'rmse': -1, 'inliers': 14}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 1200, 'rmse': -1, 'inliers': 14}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 2000, 'rmse': -1, 'inliers': 14}\n",
      "\n",
      "max memory allocated cuda 1668168704\n",
      "(560, 2) (25, 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ph \u001B[38;5;129;01min\u001B[39;00m paths:\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(test_for_each_pair):\n\u001B[0;32m---> 22\u001B[0m         results, entropy \u001B[38;5;241m=\u001B[39m \u001B[43mdo_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmatcher_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_search\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43msize_patch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m240\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m240\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mconfigs_ransac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigs_ransac\u001B[49m\u001B[43m,\u001B[49m\u001B[43mthreshold_inliers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mrandom_select\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m results \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     30\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(results)):\n",
      "Cell \u001B[0;32mIn[43], line 39\u001B[0m, in \u001B[0;36mdo_test\u001B[0;34m(matcher_in, ph, size_search, size_patch, threshold_inliers, configs_ransac, verbose, random_select)\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmeasure\u001B[39;00m\n\u001B[0;32m---> 39\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_and_print\u001B[49m\u001B[43m(\u001B[49m\u001B[43mph\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrgb_img1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrgb_img2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatcher_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_window_source\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_dest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints_patch\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpoints_patch_ref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m                             \u001B[49m\u001B[43msize_search\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_search\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_patch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_patch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m                            \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfigs_ransac\u001B[49m\u001B[43m,\u001B[49m\u001B[43mthreshold_inliers\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrandom_select\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m                           \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m entropy \u001B[38;5;241m=\u001B[39m skimage\u001B[38;5;241m.\u001B[39mmeasure\u001B[38;5;241m.\u001B[39mshannon_entropy(patch_dest)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results, entropy\n",
      "Cell \u001B[0;32mIn[41], line 236\u001B[0m, in \u001B[0;36mpredict_and_print\u001B[0;34m(ph, rgb_img1, rgb_img2, matcher, img0_raw, img1_raw, points, points_patch, points_patch_ref, searching_window_w, searching_window_h, patch_w, patch_h, configs_ransac, threshold_inliers, random_select)\u001B[0m\n\u001B[1;32m    233\u001B[0m     mconf \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmconf\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mkpts0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [postproces_and_metric(conf, mkpts0, mkpts1, img0, ph, points, points_patch,points_patch_ref,\n\u001B[1;32m    237\u001B[0m                                        searching_window_w, searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2,\n\u001B[1;32m    238\u001B[0m                                        mconf, threshold_inliers,random_select) \u001B[38;5;28;01mfor\u001B[39;00m conf \u001B[38;5;129;01min\u001B[39;00m configs_ransac]\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[41], line 236\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    233\u001B[0m     mconf \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmconf\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mkpts0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mpostproces_and_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmkpts0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmkpts1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoints_patch\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpoints_patch_ref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43msearching_window_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearching_window_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrgb_img1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrgb_img2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mmconf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold_inliers\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrandom_select\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m conf \u001B[38;5;129;01min\u001B[39;00m configs_ransac]\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[41], line 207\u001B[0m, in \u001B[0;36mpostproces_and_metric\u001B[0;34m(conf, mkpts0, mkpts1, img0, ph, points, points_patch, points_patch_ref, searching_window_w, searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2, mconf, threshold_inliers, random_select, save_pdf)\u001B[0m\n\u001B[1;32m    204\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[1;32m    205\u001B[0m                fig \u001B[38;5;241m=\u001B[39m make_matching_figure(rgb_img1, rgb_img2, abs_m0, abs_m1, color, abs_m0[:\u001B[38;5;241m1\u001B[39m], abs_m1,\n\u001B[1;32m    206\u001B[0m                                        text)\n\u001B[0;32m--> 207\u001B[0m         \u001B[43mmake_matching_figure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb_img1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrgb_img2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabs_m0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabs_m1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabs_m0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabs_m1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmagsacpp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresidual_threshold\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_rmse_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrmse\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_inliers_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn_inliers\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.pdf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m conf\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/LoFTR-master/src/utils/plotting.py:25\u001B[0m, in \u001B[0;36mmake_matching_figure\u001B[0;34m(img0, img1, mkpts0, mkpts1, color, kpts0, kpts1, text, dpi, path)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_matching_figure\u001B[39m(\n\u001B[1;32m     21\u001B[0m         img0, img1, mkpts0, mkpts1, color,\n\u001B[1;32m     22\u001B[0m         kpts0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, kpts1\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, text\u001B[38;5;241m=\u001B[39m[], dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m75\u001B[39m, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;66;03m# draw image pair\u001B[39;00m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m mkpts0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m mkpts1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmkpts0: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmkpts0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m v.s. mkpts1: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmkpts1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 25\u001B[0m     fig, axes \u001B[38;5;241m=\u001B[39m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubplots\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfigsize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     axes[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mimshow(img0, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     27\u001B[0m     axes[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mimshow(img1, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/pyplot.py:1475\u001B[0m, in \u001B[0;36msubplots\u001B[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001B[0m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1332\u001B[0m \u001B[38;5;124;03mCreate a figure and a set of subplots.\u001B[39;00m\n\u001B[1;32m   1333\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1472\u001B[0m \n\u001B[1;32m   1473\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1474\u001B[0m fig \u001B[38;5;241m=\u001B[39m figure(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfig_kw)\n\u001B[0;32m-> 1475\u001B[0m axs \u001B[38;5;241m=\u001B[39m \u001B[43mfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubplots\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mncols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mncols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msharex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msharey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharey\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1476\u001B[0m \u001B[43m                   \u001B[49m\u001B[43msqueeze\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubplot_kw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubplot_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1477\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mgridspec_kw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgridspec_kw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight_ratios\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheight_ratios\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1478\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mwidth_ratios\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwidth_ratios\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1479\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fig, axs\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/figure.py:892\u001B[0m, in \u001B[0;36mFigureBase.subplots\u001B[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001B[0m\n\u001B[1;32m    889\u001B[0m     gridspec_kw[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwidth_ratios\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m width_ratios\n\u001B[1;32m    891\u001B[0m gs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_gridspec(nrows, ncols, figure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgridspec_kw)\n\u001B[0;32m--> 892\u001B[0m axs \u001B[38;5;241m=\u001B[39m \u001B[43mgs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubplots\u001B[49m\u001B[43m(\u001B[49m\u001B[43msharex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msharey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msqueeze\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m                  \u001B[49m\u001B[43msubplot_kw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubplot_kw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m axs\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/gridspec.py:299\u001B[0m, in \u001B[0;36mGridSpecBase.subplots\u001B[0;34m(self, sharex, sharey, squeeze, subplot_kw)\u001B[0m\n\u001B[1;32m    297\u001B[0m         subplot_kw[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msharex\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m shared_with[sharex]\n\u001B[1;32m    298\u001B[0m         subplot_kw[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msharey\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m shared_with[sharey]\n\u001B[0;32m--> 299\u001B[0m         axarr[row, col] \u001B[38;5;241m=\u001B[39m \u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_subplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msubplot_kw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;66;03m# turn off redundant tick labeling\u001B[39;00m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sharex \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/figure.py:743\u001B[0m, in \u001B[0;36mFigureBase.add_subplot\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    740\u001B[0m         args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m(args[\u001B[38;5;241m0\u001B[39m])))\n\u001B[1;32m    741\u001B[0m     projection_class, pkw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_projection_requirements(\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 743\u001B[0m     ax \u001B[38;5;241m=\u001B[39m \u001B[43mprojection_class\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    744\u001B[0m     key \u001B[38;5;241m=\u001B[39m (projection_class, pkw)\n\u001B[1;32m    745\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_axes_internal(ax, key)\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/axes/_base.py:672\u001B[0m, in \u001B[0;36m_AxesBase.__init__\u001B[0;34m(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;66;03m# placeholder for any colorbars added that use this Axes.\u001B[39;00m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;66;03m# (see colorbar.py):\u001B[39;00m\n\u001B[1;32m    671\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_colorbars \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 672\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspines \u001B[38;5;241m=\u001B[39m mspines\u001B[38;5;241m.\u001B[39mSpines\u001B[38;5;241m.\u001B[39mfrom_dict(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gen_axes_spines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    674\u001B[0m \u001B[38;5;66;03m# this call may differ for non-sep axes, e.g., polar\u001B[39;00m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_axis()\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/axes/_base.py:1221\u001B[0m, in \u001B[0;36m_AxesBase._gen_axes_spines\u001B[0;34m(self, locations, offset, units)\u001B[0m\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_gen_axes_spines\u001B[39m(\u001B[38;5;28mself\u001B[39m, locations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, offset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, units\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minches\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m   1207\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;124;03m    -------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;124;03m    Intended to be overridden by new projection types.\u001B[39;00m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {side: mspines\u001B[38;5;241m.\u001B[39mSpine\u001B[38;5;241m.\u001B[39mlinear_spine(\u001B[38;5;28mself\u001B[39m, side)\n\u001B[1;32m   1222\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m side \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbottom\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/axes/_base.py:1221\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_gen_axes_spines\u001B[39m(\u001B[38;5;28mself\u001B[39m, locations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, offset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, units\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minches\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m   1207\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;124;03m    -------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;124;03m    Intended to be overridden by new projection types.\u001B[39;00m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {side: \u001B[43mmspines\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSpine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_spine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mside\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1222\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m side \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbottom\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/spines.py:440\u001B[0m, in \u001B[0;36mSpine.linear_spine\u001B[0;34m(cls, axes, spine_type, **kwargs)\u001B[0m\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munable to make path for spine \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m spine_type)\n\u001B[1;32m    439\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(axes, spine_type, path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 440\u001B[0m result\u001B[38;5;241m.\u001B[39mset_visible(\u001B[43mmpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrcParams\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maxes.spines.\u001B[39;49m\u001B[38;5;132;43;01m{0}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspine_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/matplotlib/__init__.py:726\u001B[0m, in \u001B[0;36mRcParams.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    725\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m--> 726\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m _deprecated_map:\n\u001B[1;32m    727\u001B[0m         version, alt_key, alt_val, inverse_alt \u001B[38;5;241m=\u001B[39m _deprecated_map[key]\n\u001B[1;32m    728\u001B[0m         _api\u001B[38;5;241m.\u001B[39mwarn_deprecated(\n\u001B[1;32m    729\u001B[0m             version, name\u001B[38;5;241m=\u001B[39mkey, obj_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrcparam\u001B[39m\u001B[38;5;124m\"\u001B[39m, alternative\u001B[38;5;241m=\u001B[39malt_key)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 750x450 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "matcher_in = get_matcher(\"outdoor\", unlock=True)\n",
    "verbose = False\n",
    "random.seed(9)\n",
    "count_yes = 0\n",
    "test_for_each_pair = 1\n",
    "configs_ransac = [{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0},\n",
    "\n",
    "                  {'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 3, 'max_trials': 100},\n",
    "                  ]\n",
    "paths = get_list()\n",
    "\n",
    "metrics = [{'rmse': 0, 'inliers': 0, 'accepted_match': 0} for conf in range(len(configs_ransac))]\n",
    "\n",
    "for ph in paths:\n",
    "    for x in range(test_for_each_pair):\n",
    "\n",
    "\n",
    "        results, entropy = do_test(matcher_in, ph, size_search=(400, 400),\n",
    "                                                     size_patch=(240, 240),\n",
    "                                                     verbose=verbose,\n",
    "                                                     configs_ransac=configs_ransac,threshold_inliers=25,random_select=False)\n",
    "\n",
    "\n",
    "        if results is not None:\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if results[i]['rmse'] >= 0:\n",
    "\n",
    "\n",
    "                    metrics[i]['rmse'] += results[i]['rmse']\n",
    "                    metrics[i]['inliers'] += results[i]['inliers']\n",
    "                    metrics[i]['accepted_match'] += 1\n",
    "                print(results[i])\n",
    "                #print(metrics[i])\n",
    "\n",
    "            count_yes += 1\n",
    "\n",
    "data = []\n",
    "for i in range(len(metrics)):\n",
    "    if metrics[i]['accepted_match'] > 0:\n",
    "        metrics[i]['rmse'] /= metrics[i]['accepted_match']\n",
    "        metrics[i]['inliers'] /= metrics[i]['accepted_match']\n",
    "\n",
    "    configs_ransac[i]['rmse'] = metrics[i]['rmse']\n",
    "    configs_ransac[i]['inliers'] = metrics[i]['inliers']\n",
    "    configs_ransac[i]['Accepted_match'] = metrics[i]['accepted_match']\n",
    "    configs_ransac[i]['total_match'] = test_for_each_pair * len(paths)\n",
    "    data.append(configs_ransac[i])\n",
    "    #print(\"Configuration:\",configs_ransac[i-1],\" Metrics:\",metrics[i], \" Accepted_match:\", metrics[i]['accepted_match'] ,\"/\", test_for_each_pair*len(paths))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel('players.xlsx')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel('players.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
