{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1BgNIOjFHauFoNB95LGesHBIjioX74USW",
     "timestamp": 1678962213911
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vcYjx3HFUcw"
   },
   "source": [
    "# LoFTR evaluation on UAVSAR - ICEYE\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC8lRUbftBby",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309391118,
     "user_tz": -60,
     "elapsed": 22860,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "outputId": "7e38fc25-a09a-4667-cf0a-42fbcbebd9d0"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWjHASahGCjv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309399431,
     "user_tz": -60,
     "elapsed": 8321,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "outputId": "c214f310-7e2c-4d81-b062-0950d308320c"
   },
   "source": [],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RD9G7vCzFUc1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309487490,
     "user_tz": -60,
     "elapsed": 3731,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ee2c4ab-9864-4776-fbb7-7500a8c5c6c1"
   },
   "source": [
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy.ndimage import uniform_filter, variance\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "from config.defaultmf import get_cfg_defaults\n",
    "from model.lightning_loftr import PL_LoFTR\n",
    "! pip install rasterio\n",
    "import rasterio as rio\n",
    "from rasterio import warp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "import torch\n",
    "# Need this to plot in HD\n",
    "# This takes up a lot of memory!\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (1.3.5.post1)\r\n",
      "Requirement already satisfied: click-plugins in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.1.1)\r\n",
      "Requirement already satisfied: attrs in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (22.2.0)\r\n",
      "Requirement already satisfied: setuptools in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (65.6.3)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: click>=4.0 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (8.1.3)\r\n",
      "Requirement already satisfied: numpy>=1.18 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.23.4)\r\n",
      "Requirement already satisfied: affine in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2.4.0)\r\n",
      "Requirement already satisfied: certifi in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2022.12.7)\r\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_correspondence(i,j,llh_array, transform, crs):\n",
    "    ''' Given row and column in SLC image, get corresponding row and column in rasterio dataset.\n",
    "    @param i: row in slc.\n",
    "    @param j: column in slc.\n",
    "    @param llh_array: the llh as a dictionary of numpy arrays (one per lat, long, height).\n",
    "    @param grd_ds: the grd as a rasterio dataset.\n",
    "    @param transform: the geotransform of the rasterio dataset.\n",
    "    @param crs: the crs of the rasterio dataset.\n",
    "    @return i_ref: row in grd.\n",
    "    @return j_ref: column in grd.\n",
    "    '''\n",
    "    lat = llh_array[f'llh.lat'][i][j]\n",
    "    lon = llh_array[f'llh.long'][i][j]\n",
    "    # Convert the EPSG:4326 coordinate to the CRS of the raster\n",
    "    X, Y = warp.transform(crs, CRS.from_string(\"EPSG:4326\"), [lon], [lat])\n",
    "    # Calculate the corresponding pixel coordinate\n",
    "    # i_ref, j_ref = dataset_ref.index(X, Y)\n",
    "    j_ref, i_ref = ~transform * (X[0],Y[0])\n",
    "    i_ref = round(i_ref)\n",
    "    j_ref = round(j_ref)\n",
    "    return i_ref, j_ref"
   ],
   "metadata": {
    "id": "781-Dbg9ZeIK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309412441,
     "user_tz": -60,
     "elapsed": 34,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fMqIOuSzFUc2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309435250,
     "user_tz": -60,
     "elapsed": 22838,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "outputId": "06c8e2a7-466c-4fe7-85ef-1373b8b76199"
   },
   "source": [
    "# The default config uses dual-softmax.\n",
    "# The outdoor and indoor models share the same config.\n",
    "# You can change the default values like thr and coarse_match_type.\n",
    "config = get_cfg_defaults()\n",
    "#config.merge_from_file(args.data_cfg_path)\n",
    "pl.seed_everything(config.TRAINER.SEED)  # reproducibility\n",
    "\n",
    "# lightning module\n",
    "\n",
    "matcher = PL_LoFTR(config, pretrained_ckpt=\"./weights/outdoor-lite-SEA.ckpt\", dump_dir=\".\")\n",
    "\n",
    "matcher=  matcher.cuda().eval()\n",
    "\n",
    "\n",
    "\n",
    "# try with pairs 8, 7, 6, 5, 4\n",
    "\n",
    "pair_n = 8\n",
    "\n",
    "img0_pth = f\"./data/UAVSAR/pair_{pair_n}/1.jpg\"\n",
    "img1_pth = f\"./data/UAVSAR/pair_{pair_n}/2.jpg\"\n",
    "image_pair = [img0_pth, img1_pth]\n",
    "\n",
    "img0_raw =cv2.imread(image_pair[0], cv2.IMREAD_GRAYSCALE)\n",
    "img1_raw = cv2.imread(image_pair[1], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "#img0_raw = cv2.resize(img0_raw, (img0_raw.shape[1]//8*8, img0_raw.shape[0]//8*8))  # input size shuold be divisible by 8\n",
    "#img1_raw = cv2.resize(img1_raw, (img1_raw.shape[1]//8*8, img1_raw.shape[0]//8*8))\n",
    "\n",
    "img0 = torch.from_numpy(img0_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "img1 = torch.from_numpy(img1_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "\n",
    "batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "# Inference with LoFTR and get prediction\n",
    "with torch.no_grad():\n",
    "\n",
    "    matcher.matcher(batch)\n",
    "    mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "    mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "    mconf = batch['mconf'].cpu().numpy()\n",
    "# Draw \n",
    "color = cm.jet(mconf, alpha=0.7)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, mkpts0, mkpts1, text)\n",
    "\n",
    "# A high-res PDF will also be downloaded automatically.\n",
    "make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, mkpts0, mkpts1, text, path=\"LoFTR-colab-demo.pdf\")\n"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 66\n",
      "2023-03-22 10:30:08.123 | INFO     | model.lightning_loftr:__init__:34 - Load './weights/outdoor-lite-SEA.ckpt' as pretrained checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1200, 1200]) torch.Size([1, 1, 800, 800])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "split_size can only be 0 if dimension size is 0, but got dimension size of 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Inference with LoFTR and get prediction\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 39\u001B[0m     \u001B[43mmatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     mkpts0 \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmkpts0_f\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m     41\u001B[0m     mkpts1 \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmkpts1_f\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/MatchFormer/MatchFormer-main/model/matchformer.py:36\u001B[0m, in \u001B[0;36mMatchformer.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     34\u001B[0m     (feat_c0, feat_c1),(feat_f0, feat_f1) \u001B[38;5;241m=\u001B[39m feats_c\u001B[38;5;241m.\u001B[39msplit(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbs\u001B[39m\u001B[38;5;124m'\u001B[39m]),feats_f\u001B[38;5;241m.\u001B[39msplit(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbs\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 36\u001B[0m     (feat_c0, feat_f0), (feat_c1, feat_f1) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage1\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     38\u001B[0m data\u001B[38;5;241m.\u001B[39mupdate({\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhw0_c\u001B[39m\u001B[38;5;124m'\u001B[39m: feat_c0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhw1_c\u001B[39m\u001B[38;5;124m'\u001B[39m: feat_c1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:],\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhw0_f\u001B[39m\u001B[38;5;124m'\u001B[39m: feat_f0\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhw1_f\u001B[39m\u001B[38;5;124m'\u001B[39m: feat_f1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m:]\n\u001B[1;32m     41\u001B[0m })\n\u001B[1;32m     43\u001B[0m feat_c0 \u001B[38;5;241m=\u001B[39m rearrange(feat_c0, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn c h w -> n (h w) c\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/MatchFormer/MatchFormer-main/model/backbone/match_SEA_lite.py:264\u001B[0m, in \u001B[0;36mMatchformer_SEA_lite.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;66;03m# stage 1 # 1/4        \u001B[39;00m\n\u001B[0;32m--> 264\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAttentionBlock1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    265\u001B[0m     out1 \u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;66;03m# stage 2 # 1/8\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/MatchFormer/MatchFormer-main/model/backbone/match_SEA_lite.py:201\u001B[0m, in \u001B[0;36mAttentionBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    199\u001B[0m x, H, W  \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_embed(x)\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock):\n\u001B[0;32m--> 201\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x)\n\u001B[1;32m    203\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(B, H, W, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/MatchFormer/MatchFormer-main/model/backbone/match_SEA_lite.py:143\u001B[0m, in \u001B[0;36mBlock.forward\u001B[0;34m(self, x, H, W)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, H, W):\n\u001B[0;32m--> 143\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_path(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    144\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_path(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x), H, W))\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LoFTR-master/MatchFormer/MatchFormer-main/model/backbone/match_SEA_lite.py:79\u001B[0m, in \u001B[0;36mAttention.forward\u001B[0;34m(self, x, H, W)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;66;03m#cross attention\u001B[39;00m\n\u001B[1;32m     78\u001B[0m q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq(x)\u001B[38;5;241m.\u001B[39mreshape(B, N, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, C \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 79\u001B[0m q1,q2 \u001B[38;5;241m=\u001B[39m \u001B[43mq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMiniB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msr_ratio \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     82\u001B[0m     x_ \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(B, C, H, W)\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/torch/_tensor.py:787\u001B[0m, in \u001B[0;36mTensor.split\u001B[0;34m(self, split_size, dim)\u001B[0m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(split_size, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m--> 787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    789\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_VF\u001B[38;5;241m.\u001B[39msplit_with_sizes(\u001B[38;5;28mself\u001B[39m, split_size, dim)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: split_size can only be 0 if dimension size is 0, but got dimension size of 1"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Affine transform estimation with RANSAC"
   ],
   "metadata": {
    "id": "80QMfu8JZ8hL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "keypoints_left = mkpts0\n",
    "keypoints_right = mkpts1\n",
    "np.random.seed(0)\n",
    "model, inliers = ransac(\n",
    "    (keypoints_left, keypoints_right),\n",
    "    AffineTransform, min_samples=4, #ProjectiveTransform\n",
    "    residual_threshold=4, max_trials=10000\n",
    ")\n",
    "n_inliers = np.sum(inliers)\n",
    "\n",
    "print('Number of inliers: %d.' % n_inliers)\n",
    "inlier_keypoints_left = [cv2.KeyPoint(point[0], point[1], 1) for point in keypoints_left[inliers]]\n",
    "inlier_keypoints_right = [cv2.KeyPoint(point[0], point[1], 1) for point in keypoints_right[inliers]]\n",
    "placeholder_matches = [cv2.DMatch(idx, idx, 1) for idx in range(n_inliers)]\n",
    "image3 = cv2.drawMatches(img0_raw, inlier_keypoints_left, img1_raw, inlier_keypoints_right, placeholder_matches, None)\n",
    "\n",
    "# load llh\n",
    "with open(f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/2_llh.npy\", 'rb') as f:\n",
    "    query_lat = np.load(f)\n",
    "    query_long = np.load(f)\n",
    "llh = {}\n",
    "llh[f'llh.lat'] = query_lat\n",
    "llh[f'llh.long'] = query_long\n",
    "\n",
    "# load geotransform\n",
    "with open(f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/1_tf_crs.npy\", 'rb') as f:\n",
    "    transform = np.load(f)\n",
    "    transform = tform.Affine(*transform.flatten()[:6])\n",
    "    crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "kpidx = 24\n",
    "\n",
    "# Visualize single match and ground truth\n",
    "corr_i, corr_j = get_correspondence(int(inlier_keypoints_right[kpidx].pt[1]), \n",
    "                                    int(inlier_keypoints_right[kpidx].pt[0]), \n",
    "                                    llh, transform, crs)\n",
    "\n",
    "print(f\"SLC kp: {inlier_keypoints_right[kpidx].pt[1]}, {inlier_keypoints_right[kpidx].pt[0]}\")\n",
    "print(f\"GRD kp: {inlier_keypoints_left[kpidx].pt[1]}, {inlier_keypoints_left[kpidx].pt[0]}\")\n",
    "print(f\"GRD kp GT: {corr_i},  {corr_j}\")\n",
    "\n",
    "# plot single correspondence\n",
    "plt.subplot(121)\n",
    "plot = cv2.cvtColor(img0_raw, cv2.COLOR_GRAY2RGB)\n",
    "plot = cv2.circle(plot, (corr_j, corr_i), 15, (255,0,0), 3)\n",
    "plot = cv2.circle(plot, (int(inlier_keypoints_left[kpidx].pt[0]), int(inlier_keypoints_left[kpidx].pt[1])), 15, (0,0,255), 3)\n",
    "plt.imshow(plot, interpolation='nearest', cmap = 'gray')\n",
    "plt.title('Search', fontweight =\"bold\")\n",
    "plt.subplot(122)\n",
    "plot = cv2.cvtColor(img1_raw, cv2.COLOR_GRAY2RGB)\n",
    "plot = cv2.circle(plot, (int(inlier_keypoints_right[kpidx].pt[0]), int(inlier_keypoints_right[kpidx].pt[1])), 15, (0,0,255), 3)\n",
    "plt.imshow(plot, interpolation='nearest', cmap = 'gray')\n",
    "plt.title('Query', fontweight =\"bold\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(image3)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "id": "t9KZYVxKyOnc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1679309451492,
     "user_tz": -60,
     "elapsed": 16260,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "outputId": "46c15a6d-8dbb-4a90-daf0-aa1117f89459"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate - Get RMSE"
   ],
   "metadata": {
    "id": "NLNqW2Gh2RXP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tot_pairs = 100\n",
    "\n",
    "# For each of the pairs\n",
    "errors = []\n",
    "for pair_n in tqdm(range(tot_pairs)):\n",
    "\n",
    "  img0_pth = f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/1.jpg\" # SEARCH - SATELLITE\n",
    "  img1_pth = f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/2.jpg\" # QUERY - UAV\n",
    "  image_pair = [img0_pth, img1_pth]\n",
    "  img0_raw = cv2.imread(image_pair[0], cv2.IMREAD_GRAYSCALE)\n",
    "  img1_raw = cv2.imread(image_pair[1], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "  # Input size shuold be divisible by 8\n",
    "  assert(img0_raw.shape[1] % 8 == 0 and img0_raw.shape[0] % 8 == 0)\n",
    "  # img0_raw = cv2.resize(img0_raw, (img0_raw.shape[1]//8*8, img0_raw.shape[0]//8*8)) \n",
    "  # img1_raw = cv2.resize(img1_raw, (img1_raw.shape[1]//8*8, img1_raw.shape[0]//8*8))\n",
    "\n",
    "  img0 = torch.from_numpy(img0_raw)[None][None].cuda() / 255.\n",
    "  img1 = torch.from_numpy(img1_raw)[None][None].cuda() / 255.\n",
    "  batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "  # Inference with LoFTR and get prediction\n",
    "  with torch.no_grad():\n",
    "      matcher(batch)\n",
    "      mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "      mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "      mconf = batch['mconf'].cpu().numpy()\n",
    "\n",
    "  # RANSAC\n",
    "  keypoints_left = mkpts0\n",
    "  keypoints_right = mkpts1\n",
    "  np.random.seed(0)\n",
    "  model, inliers = ransac(\n",
    "      (keypoints_left, keypoints_right),\n",
    "      AffineTransform, min_samples=4, #ProjectiveTransform\n",
    "      residual_threshold=4, max_trials=10000\n",
    "  )\n",
    "  n_inliers = np.sum(inliers)\n",
    "\n",
    "  print(\"\\n ------------------\")\n",
    "  print(f'Pair {pair_n} - Number of inliers: {n_inliers}')\n",
    "\n",
    "  # If too few inliers, discard pair!\n",
    "  if n_inliers < 50 :\n",
    "    print(\"Too few inliers -> discarding pair\")\n",
    "    continue\n",
    "\n",
    "  # load llh\n",
    "  with open(f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/2_llh.npy\", 'rb') as f:\n",
    "      query_lat = np.load(f)\n",
    "      query_long = np.load(f)\n",
    "  llh = {}\n",
    "  llh[f'llh.lat'] = query_lat\n",
    "  llh[f'llh.long'] = query_long\n",
    "\n",
    "  # load geotransform\n",
    "  with open(f\"/content/drive/MyDrive/UAVSAR - ICEYE/San Francisco/pairs/pair_{pair_n}/1_tf_crs.npy\", 'rb') as f:\n",
    "      transform = np.load(f)\n",
    "      transform = tform.Affine(*transform.flatten()[:6])\n",
    "      crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "  # For each inlier\n",
    "  errors_pair = []\n",
    "  indices = np.where(inliers == True)\n",
    "  for idx in np.nditer(indices):\n",
    "\n",
    "    idx = round(idx.item())\n",
    "\n",
    "    i_slc, j_slc = round(mkpts1[idx,1]), round(mkpts1[idx,0]) # QUERY - UAV\n",
    "\n",
    "    i_grd, j_grd = round(mkpts0[idx,1]), round(mkpts0[idx,0]) # SEARCH - SAT\n",
    "\n",
    "    # Given point in SLC, get correspondence in GRD \n",
    "    i_ref, j_ref = get_correspondence(i_slc, j_slc, llh, transform, crs)\n",
    "\n",
    "    # Compute RMSE contribution - append square distance\n",
    "    errors_pair.append((i_grd - i_ref)**2 + (j_grd - j_ref)**2)\n",
    "    errors.append((i_grd - i_ref)**2 + (j_grd - j_ref)**2)\n",
    "  \n",
    "  # Plot RMSE for each pair\n",
    "  errors_np = np.asarray(errors_pair)\n",
    "  rmse = sqrt(np.sum(errors_np)/errors_np.size)\n",
    "  print(\"RMSE: \", rmse)\n",
    "\n",
    "# Compute RMSE - average and root\n",
    "errors_np = np.asarray(errors)\n",
    "rmse = sqrt(np.sum(errors_np)/errors_np.size)\n",
    "print(\"Final RMSE: \", rmse)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "id": "5K3WGs8f2RDe",
    "executionInfo": {
     "status": "error",
     "timestamp": 1679309837143,
     "user_tz": -60,
     "elapsed": 82716,
     "user": {
      "displayName": "Villaggio2 Cloud2",
      "userId": "13519401399908192170"
     }
    },
    "outputId": "516040a5-41be-4e4d-b77b-569979136b15"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
