{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIGuQbmAl3-q"
   },
   "source": [
    "# Readme: how to handle our Sentinel-1 ASC-DESC dataset\n",
    "\n",
    "###What you have: \n",
    "A list of big geotiff file (.tif) Pairs. Each image in the pair should roughly correspond to the same area as the other. Each geotiff can by read using rasterio or gdal, as you can see in the notebook.\n",
    "\n",
    "###What you should do: \n",
    "create single datapoints to train/test your models.\n",
    "\n",
    "###How to do it: \n",
    "For each big pair, get a datapoint by cropping a random patch from one side (this acts as the \"query\" patch, the one you want to look for) and cropping a patch around the same coordinates from the other side (this acts as the \"search\" patch, the one to want to search in). Add distortions: search patch has to be taken with a random offset around query patch (perhaps random but normally distributed around offset 0, which means query patch at the centre). Also add a bit of random scale and rotation.Try finding a 1km^2 query patch inside a 4km^2 search patch. \n",
    "\n",
    "###Some WARNINGS (not too sure about them)\n",
    "\n",
    "Warning: do not include every correspondence in the ground truth pixel correspondence list! you should only insert meaningful correspondences such as harris corners.\n",
    "\n",
    "Warning: maybe discard a candidate query altogether if it's not feature-rich enough. You can do this using pixel histograms (has to have more than n peaks -> use scikit learn), or maybe entropy. for example, if every pixel is around e.g. 150, this means that everything is gray and unmatchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (1.3.5.post1)\r\n",
      "Requirement already satisfied: click-plugins in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.1.1)\r\n",
      "Requirement already satisfied: click>=4.0 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (8.1.3)\r\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.4.7)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: numpy>=1.18 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (1.23.4)\r\n",
      "Requirement already satisfied: attrs in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (22.2.0)\r\n",
      "Requirement already satisfied: setuptools in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (65.6.3)\r\n",
      "Requirement already satisfied: certifi in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2022.12.7)\r\n",
      "Requirement already satisfied: affine in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from rasterio) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/fred/anaconda3/envs/pythonProject/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\r\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from pymagsac import pymagsac\n",
    "from scipy.ndimage import uniform_filter, variance\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "from config.defaultmf import get_cfg_defaults\n",
    "from model.lightning_loftr import PL_LoFTR\n",
    "from rasterio.crs import CRS\n",
    "from rasterio import transform as tform\n",
    "\n",
    "! pip install rasterio\n",
    "import rasterio as rio\n",
    "from rasterio import warp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import argparse\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Need thsxdfsdfis to plot in HD\n",
    "# This takes up a lot of memory!\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "if 'model_TransSAR' not in locals():\n",
    "    model_TransSAR = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "def get_correspondence(i, j, llh_array, transform, crs):\n",
    "    ''' Given row and column in SLC image, get corresponding row and column in rasterio dataset.\n",
    "    @param i: row in slc.\n",
    "    @param j: column in slc.\n",
    "    @param llh_array: the llh as a dictionary of numpy arrays (one per lat, long, height).\n",
    "    @param grd_ds: the grd as a rasterio dataset.\n",
    "    @param transform: the geotransform of the rasterio dataset.\n",
    "    @param crs: the crs of the rasterio dataset.\n",
    "    @return i_ref: row in grd.\n",
    "    @return j_ref: column in grd.\n",
    "    '''\n",
    "    i = round(i)\n",
    "    j = round(j)\n",
    "    lat = llh_array[f'llh.lat'][i][j]\n",
    "    lon = llh_array[f'llh.long'][i][j]\n",
    "    # Convert the EPSG:4326 coordinate to the CRS of the raster\n",
    "    X, Y = warp.transform(crs, CRS.from_string(\"EPSG:4326\"), [lon], [lat])\n",
    "    # Calculate the corresponding pixel coordinate\n",
    "    # i_ref, j_ref = dataset_ref.index(X, Y)\n",
    "    j_ref, i_ref = ~transform * (X[0], Y[0])\n",
    "    i_ref = round(i_ref)\n",
    "    j_ref = round(j_ref)\n",
    "    return i_ref, j_ref\n",
    "\n",
    "def get_datapoint(ref_data, query_data):\n",
    "    ''' TODO: Call this method on a pair of rasterio datasets. It will generate a random datapoint consisting\n",
    "        of a smaller SAR patch from the query dataset, and a bigger SAR patch from the reference dataset.\n",
    "        The search patch contains the area of the smaller patch, with a random offset.\n",
    "    '''\n",
    "    datapoint = None\n",
    "    return datapoint\n",
    "\n",
    "\n",
    "def is_good_patch(patch):\n",
    "    ''' TODO: Checks if the random query patch is sufficiently texture-rich to be used to train/test the matching model.\n",
    "        If the patch is too plain (e.g. sea or desert), returns False. This function should also be used at test time:\n",
    "        if a sensor image is too plain, there's no need to match it.\n",
    "        At test time, something similar should also be done on the reference side.\n",
    "    '''\n",
    "    good = None\n",
    "    return good\n",
    "\n",
    "\n",
    "def get_keypoints(patch):\n",
    "    ''' TODO: Use something like harris corner detection to get the list of ground truth correspondences.\n",
    "        In fact, you should not train on each pixel corresp, but you should select only meaningful corresp!\n",
    "        Harris peaks might be just strong speckle noise, but if you take strong ones you should be fine.\n",
    "    '''\n",
    "    keypoints = None\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def normalize_image(img):\n",
    "    ''' Normalize by clipping to 99th percentile and convert to uint8.\n",
    "        This clips strong speckle outliers and optimizes the brightness range\n",
    "    '''\n",
    "    p1 = np.nanpercentile(img, 99)\n",
    "    img = img.clip(0, p1)\n",
    "    img = (img - np.nanmin(img)) / (np.nanmax(img) - np.nanmin(img)) * 255\n",
    "    img = img.astype(np.uint8, copy=True)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "paths = [\n",
    "    './data/paired_sentinel/Sentinel1-AD Dataset- Lat-0.015502064951149919Lon41.3552557262833/S1A_IW_GRDH_1SDV_20220808T060138_20220808T060203_044457_054E18_B16D.tif',\n",
    "    './data/paired_sentinel/Sentinel1-AD Dataset- Lat-0.015502064951149919Lon41.3552557262833/S1A_IW_GRDH_1SDV_20220814T175523_20220814T175548_044552_055140_2AEA.tif']\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def get_sample(ph, search_window, patch_size, margin=80, random_seed=1, verbose=True,\n",
    "               random_rotation=0.03, random_zoom=0.03,inner_margin=30):\n",
    "    '''\n",
    "          1-Reads the first band of the TIFF files using the rio library and normalizes the image data.\n",
    "          2-Selects a random search window and patch location within the image using random number generators.\n",
    "          3-Calls the get_correspondence function on the selected locations to find the corresponding locations in the second image.\n",
    "          4-Converts the grayscale images to RGB format using OpenCV.\n",
    "          5-Creates centered patches from the RGB images by zero-padding the images and copying a portion of the original images to the patches.\n",
    "          6-Draws rectangles around the search window and patch in both images.\n",
    "          7-Saves the patch and search window as JPEG files.\n",
    "          8-Returns the processed RGB images, the points of the search window and patch, and the original rio datasets.\n",
    "\n",
    "    '''\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    img1 = cv2.imread(p1, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(p2, cv2.IMREAD_GRAYSCALE)\n",
    "    img1 = cv2.resize(img1, (img1.shape[1]//8*8, img1.shape[0]//8*8))  # input size shuold be divisible by 8\n",
    "    img2 = cv2.resize(img2, (img2.shape[1]//8*8, img2.shape[0]//8*8))\n",
    "\n",
    "\n",
    "    img1 = np.swapaxes(img1, 0, 1)\n",
    "    img2 = np.swapaxes(img2, 0, 1)\n",
    "\n",
    "    search_window_w, search_window_h = search_window\n",
    "    patch_size_w, patch_size_h = patch_size\n",
    "\n",
    "    if img1.shape[0] - search_window_w - margin * 2 < 0 or img1.shape[1] - search_window_h - margin * 2 < 0:\n",
    "        print(\"margin + search windows is too big for the image:\", margin, \"*2 +\", (search_window_w, search_window_h),\n",
    "              \">\", img1.shape)\n",
    "        return None, None, None, None, None, None, None\n",
    "    lu = (margin + random.randint(0, img1.shape[0] - search_window_w - margin * 2),\n",
    "          margin + random.randint(0, img1.shape[1] - search_window_h - margin * 2))\n",
    "    rd = (lu[0] + search_window_w ,  lu[1] + search_window_h)\n",
    "    lu_patch = (lu[0] + inner_margin+ random.randint(0, search_window_w - patch_size_w- 2* inner_margin),\n",
    "                lu[1] + inner_margin + random.randint(0, search_window_h - patch_size_h- 2* inner_margin))\n",
    "    rd_patch = (lu_patch[0] + search_window_w ,  lu_patch[1] + search_window_h)\n",
    "\n",
    "    points_patch = lu_patch\n",
    "    points = lu\n",
    "    #print(points,\"points\",img1.shape)\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    # load llh\n",
    "    with open(hhl_path, 'rb') as f:\n",
    "        query_lat = np.load(f)\n",
    "        query_long = np.load(f)\n",
    "    llh = {}\n",
    "    llh[f'llh.lat'] = query_lat\n",
    "    llh[f'llh.long'] = query_long\n",
    "\n",
    "    # load geotransform\n",
    "    with open(crs_path, 'rb') as f:\n",
    "        trans = np.load(f)\n",
    "        trans = tform.Affine(*trans.flatten()[:6])\n",
    "        crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "\n",
    "    points_ref = get_correspondence(lu[0], lu[1], llh, trans, crs)\n",
    "    points_patch_ref = get_correspondence(lu_patch[0],lu_patch[1] , llh, trans, crs)\n",
    "\n",
    "    rgb_img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "    rgb_img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    patch_source = np.zeros((search_window_w, search_window_h), dtype=np.uint8)\n",
    "\n",
    "    patch_source[int(search_window_w / 2 - patch_size_w / 2):int(search_window_w / 2 + patch_size_w / 2),\n",
    "    int(search_window_h / 2 - patch_size_h / 2):int(search_window_h / 2 + patch_size_h / 2)] = img1[points_patch[0]:\n",
    "                                                                                                    points_patch[\n",
    "                                                                                                        0] + patch_size_w,\n",
    "                                                                                               points_patch[1]:\n",
    "                                                                                               points_patch[\n",
    "                                                                                                   1] + patch_size_h]\n",
    "\n",
    "    patch_dest = np.zeros((search_window_w, search_window_h), dtype=np.uint8)\n",
    "    patch_dest[int(search_window_w / 2 - patch_size_w / 2):int(search_window_w / 2 + patch_size_w / 2),\n",
    "    int(search_window_h / 2 - patch_size_h / 2):int(search_window_h / 2 + patch_size_h / 2)] = img2[points_patch_ref[0]:\n",
    "                                                                                                    points_patch_ref[\n",
    "                                                                                                        0] + patch_size_w,\n",
    "                                                                                               points_patch_ref[1]:\n",
    "                                                                                               points_patch_ref[\n",
    "                                                                                                   1] + patch_size_h]\n",
    "\n",
    "    search_window_source = img1[points[0]:points[0] + search_window_w, points[1]:points[1] + search_window_h]\n",
    "    search_window_dest = img2[points_ref[0]:points_ref[0] + search_window_w,\n",
    "                         points_ref[1]: points_ref[1] + search_window_h]\n",
    "\n",
    "\n",
    "\n",
    "    #draw searching windows\n",
    "\n",
    "    rgb_img1 = cv2.rectangle(rgb_img1, tuple(reversed(points)),\n",
    "                             (points[1] + search_window_h, points[0] + search_window_w), (0, 0, 255), 2)\n",
    "    rgb_img1 = cv2.rectangle(rgb_img1, tuple(reversed(points_patch)),\n",
    "                             (points_patch[1] + patch_size_h, points_patch[0] + patch_size_w), (255, 0, 0), 2)\n",
    "\n",
    "    #draw patch windows\n",
    "    rgb_img2 = cv2.rectangle(rgb_img2, tuple(reversed(points_ref)),\n",
    "                             (points_ref[1] + search_window_h, points_ref[0] + search_window_w), (0, 0, 255), 2)\n",
    "    rgb_img2 = cv2.rectangle(rgb_img2, tuple(reversed(points_patch_ref)),\n",
    "                             (points_patch_ref[1] + patch_size_h, points_patch_ref[0] + patch_size_w), (255, 0, 0), 2)\n",
    "\n",
    "    #print(rgb_img1.shape,search_window_source.shape)\n",
    "\n",
    "    rgb_img1 = np.swapaxes(rgb_img1, 0, 1)\n",
    "    rgb_img2 = np.swapaxes(rgb_img2, 0, 1)\n",
    "    search_window_source = np.swapaxes(search_window_source, 0, 1)\n",
    "    patch_source = np.swapaxes(patch_source, 0, 1)\n",
    "    search_window_dest = np.swapaxes(search_window_dest, 0, 1)\n",
    "    patch_dest = np.swapaxes(patch_dest, 0, 1)\n",
    "    if verbose:\n",
    "        fig, axes = plt.subplots(2, 3)\n",
    "        axes[0, 0].set_title('source image')\n",
    "        print(rgb_img1.shape)\n",
    "        axes[0, 0].imshow(PIL.ImageOps.invert(Image.fromarray(rgb_img1)))\n",
    "\n",
    "        axes[0, 1].set_title('search window source')\n",
    "        axes[0, 1].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(search_window_source, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[0, 2].set_title('patch source')\n",
    "        axes[0, 2].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(patch_source, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[1, 0].set_title('dest image')\n",
    "        axes[1, 0].imshow(PIL.ImageOps.invert(Image.fromarray(rgb_img2)))\n",
    "\n",
    "        axes[1, 1].set_title('search window dest')\n",
    "        axes[1, 1].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(search_window_dest, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        axes[1, 2].set_title('patch dest')\n",
    "        axes[1, 2].imshow(PIL.ImageOps.invert(Image.fromarray(cv2.cvtColor(patch_dest, cv2.COLOR_GRAY2RGB))))\n",
    "\n",
    "        plt.show()\n",
    "    rgb_img1 = np.swapaxes(rgb_img1, 0, 1)\n",
    "    rgb_img2 = np.swapaxes(rgb_img2, 0, 1)\n",
    "    patch_dest = np.swapaxes(patch_dest, 0, 1)\n",
    "    search_window_source = np.swapaxes(search_window_source, 0, 1)\n",
    "\n",
    "    return patch_dest,search_window_source,rgb_img1, rgb_img2, points, points_patch_ref, points_patch\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # init a costum parser which will be added into pl.Trainer parser\n",
    "    # check documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        'data_cfg_path', type=str, default=\".\", help='data config path')\n",
    "    parser.add_argument(\n",
    "        '--ckpt_path', type=str, default=\"weights/indoor_large-SEA.ckpt\", help='path to the checkpoint')\n",
    "    parser.add_argument(\n",
    "        '--dump_dir', type=str, default=None, help=\"if set, the matching results will be dump to dump_dir\")\n",
    "    parser.add_argument(\n",
    "        '--profiler_name', type=str, default='inference', help='options: [inference, pytorch], or leave it unset')\n",
    "    parser.add_argument(\n",
    "        '--batch_size', type=int, default=1, help='batch_size per gpu')\n",
    "    parser.add_argument(\n",
    "        '--num_workers', type=int, default=2)\n",
    "    parser.add_argument(\n",
    "        '--thr', type=float, default=None, help='modify the coarse-level matching threshold.')\n",
    "\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "from plotting import make_matching_figure\n",
    "\n",
    "def get_matcher(image_type, unlock=False):\n",
    "    print(\"hello\")\n",
    "    #args = parse_args()\n",
    "    # init default-cfg and merge it with the main- and data-cfg\n",
    "    config = get_cfg_defaults()\n",
    "    #config.merge_from_file(args.data_cfg_path)\n",
    "    pl.seed_everything(config.TRAINER.SEED)  # reproducibility\n",
    "\n",
    "    # tune when testing\n",
    "    threshold = None\n",
    "    if threshold is not None:\n",
    "        config.LOFTR.MATCH_COARSE.THR = threshold\n",
    "\n",
    "    # lightning module\n",
    "\n",
    "    matcher = PL_LoFTR(config, pretrained_ckpt=\"./weights/outdoor-lite-SEA.ckpt\", dump_dir=\".\")\n",
    "\n",
    "    return matcher.cuda().eval()\n",
    "from skimage.measure import ransac\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(mkpts0_r, mkpts1_r, points, points_patch,points_patch_ref,ph, searching_window_w, searching_window_h,\n",
    "                patch_w, patch_h):\n",
    "\n",
    "\n",
    "    p1,crs_path,p2,hhl_path = ph\n",
    "    # load llh\n",
    "    with open(hhl_path, 'rb') as f:\n",
    "        query_lat = np.load(f)\n",
    "        query_long = np.load(f)\n",
    "    llh = {}\n",
    "    llh[f'llh.lat'] = query_lat\n",
    "    llh[f'llh.long'] = query_long\n",
    "\n",
    "    # load geotransform\n",
    "    with open(crs_path, 'rb') as f:\n",
    "        trans = np.load(f)\n",
    "        trans = tform.Affine(*trans.flatten()[:6])\n",
    "        crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "\n",
    "    # Extract x and y coordinates from mkpts0\n",
    "    x0, y0 = zip(*mkpts0_r)\n",
    "\n",
    "    # Apply translation to the coordinates\n",
    "    rmse = 0\n",
    "    for idx in range(len(mkpts0_r)):\n",
    "\n",
    "\n",
    "        i_slc, j_slc = round(mkpts1_r[idx,1]), round(mkpts1_r[idx,0]) # QUERY - UAV\n",
    "\n",
    "        i_grd, j_grd = round(mkpts0_r[idx,1]), round(mkpts0_r[idx,0]) # SEARCH - SAT\n",
    "        i_grd += points[0]\n",
    "        j_grd  += points[1]\n",
    "\n",
    "        j_slc = j_slc - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1]\n",
    "        i_slc = i_slc - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0]\n",
    "        # Given point in SLC, get correspondence in GRD\n",
    "        j_ref, i_ref = get_correspondence(j_slc, i_slc, llh, trans, crs)\n",
    "\n",
    "\n",
    "        rmse += (i_grd - i_ref)**2 + (j_grd - j_ref)**2\n",
    "    # Convert the translated coordinates back to tuples\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize the errors by the number of keypoints\n",
    "    num_kpts = len(mkpts1_r)\n",
    "    rmse = (rmse / num_kpts) ** (\n",
    "            1 / 2)  # like in \"A Transformer-Based Coarse-to-Fine Wide-Swath SAR Image Registration Method under Weak Texture Conditions\"\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def cornerness_friendly(gray, points, inliers,random_select=False):\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 15)\n",
    "\n",
    "    corners = np.int0(corners)\n",
    "    harris_near = np.zeros((points.shape[0])) + 500\n",
    "\n",
    "    for match in range(len(points)):\n",
    "        if inliers[match]:\n",
    "            arr = [abs(points[match][0] - corner.ravel()[0]) + abs(points[match][1] - corner.ravel()[1]) for corner in\n",
    "                   corners]\n",
    "            harris_near[match] = min(arr)\n",
    "    result= harris_near.argsort()\n",
    "    if random_select:\n",
    "      random.shuffle(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def postproces_and_metric(conf, mkpts0, mkpts1, img0, ph, points, points_patch,points_patch_ref, searching_window_w,\n",
    "                          searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2, mconf, threshold_inliers, random_select,\n",
    "                          save_pdf=True):\n",
    "    if conf['residual_threshold'] >= 0:\n",
    "\n",
    "        import time\n",
    "\n",
    "        # get the start time\n",
    "        st = time.time()\n",
    "        order = (mconf).argsort()\n",
    "        mkpts0 = mkpts0[order]\n",
    "        mkpts1 = mkpts1[order]\n",
    "        mconf = mconf[order]\n",
    "\n",
    "        probabilities = mconf+ min(mconf)\n",
    "        probabilities  /= max(probabilities )\n",
    "\n",
    "        correspondences = np.float32([ np.concatenate(( mkpts0[m] , mkpts1[m] )) for m in range(len(mkpts0))]).reshape(-1,4)\n",
    "        H, inliers = pymagsac.findHomography(\n",
    "        np.ascontiguousarray(correspondences),\n",
    "        searching_window_w, searching_window_h, searching_window_w, searching_window_h,\n",
    "        probabilities = probabilities ,\n",
    "        sampler = 4,\n",
    "        #conf = 0.,\n",
    "        use_magsac_plus_plus = False,\n",
    "            min_iters = conf['max_trials'],\n",
    "        max_iters=conf['max_trials'],\n",
    "\n",
    "        sigma_th = float(conf['residual_threshold']))\n",
    "        et = time.time()\n",
    "\n",
    "        # get the execution time\n",
    "        elapsed_time = et - st\n",
    "        print('Magsac Execution time:', elapsed_time, 'seconds inliers:', np.sum(inliers))\n",
    "\n",
    "    else:\n",
    "        inliers = np.zeros_like(range(mkpts0.shape[0]))\n",
    "        inliers[:] = True\n",
    "\n",
    "\n",
    "    threshold_inliers = threshold_inliers if threshold_inliers >= 0 else np.sum(inliers)\n",
    "    n_inliers = np.sum(inliers)\n",
    "\n",
    "    if inliers is None or n_inliers is None or n_inliers == 0 or (n_inliers < threshold_inliers) :\n",
    "        conf.update({'rmse': -1, 'inliers': 0 if n_inliers is None else n_inliers})\n",
    "    else:\n",
    "        gray = np.array(img0.cpu()).squeeze()\n",
    "        new_order = cornerness_friendly(gray, mkpts0, inliers,random_select)\n",
    "\n",
    "\n",
    "        inliers = inliers[new_order]\n",
    "        print(mkpts0.shape,mkpts0[new_order][inliers][:threshold_inliers].shape)\n",
    "\n",
    "        rmse = get_metrics(mkpts0[new_order][inliers][:threshold_inliers], mkpts1[new_order][inliers][:threshold_inliers], points,\n",
    "                           points_patch,points_patch_ref, ph,\n",
    "                           searching_window_w, searching_window_h, patch_w, patch_h)\n",
    "        conf.update({'rmse': rmse, 'inliers': n_inliers})\n",
    "        p1,crs_path,p2,hhl_path = ph\n",
    "        # load llh\n",
    "        with open(hhl_path, 'rb') as f:\n",
    "            query_lat = np.load(f)\n",
    "            query_long = np.load(f)\n",
    "        llh = {}\n",
    "        llh[f'llh.lat'] = query_lat\n",
    "        llh[f'llh.long'] = query_long\n",
    "\n",
    "        # load geotransform\n",
    "        with open(crs_path, 'rb') as f:\n",
    "            trans = np.load(f)\n",
    "            trans = tform.Affine(*trans.flatten()[:6])\n",
    "            crs = CRS.from_epsg(np.load(f))\n",
    "\n",
    "\n",
    "        if save_pdf:\n",
    "            color = cm.jet(mconf[new_order][inliers][:threshold_inliers], alpha=0.7)\n",
    "            abs_m0 = np.array([(x + points[1], y + points[0]) for x, y in mkpts0[new_order][inliers][:threshold_inliers]])\n",
    "            abs_m1 = np.array([(x - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1],\n",
    "                                y - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0]) for x, y in\n",
    "                               mkpts1[new_order][inliers][:threshold_inliers]])\n",
    "            #abs_m0 = np.array([(get_correspondence(abs_m1[0][0],abs_m1[0][1],llh, trans, crs))])\n",
    "            text = [\n",
    "                str(conf),\n",
    "                'Matches: {}'.format(len(mkpts0[new_order][inliers][:threshold_inliers])),\n",
    "                \"x - ((searching_window_h / 2) - (patch_h / 2)) + points_patch_ref[1]\",\n",
    "                \"x - ((\"+str(searching_window_h)+str(\"/2)-\") + str(patch_h) + str(\" / 2)) + \") + str(points_patch_ref[1]),\n",
    "                \"y - ((searching_window_w / 2) - (patch_w / 2)) + points_patch_ref[0])\",\n",
    "                \"y - ((\"+str(searching_window_w)+str(\"/2)-\") + str(patch_w) + str(\" / 2)) + \") + str(points_patch_ref[0]),\n",
    "            ]\n",
    "\n",
    "            if conf['residual_threshold'] <= 0.5:\n",
    "\n",
    "                if verbose:\n",
    "                   fig = make_matching_figure(rgb_img1, rgb_img2, abs_m0, abs_m1, color, abs_m0[:1], abs_m1,\n",
    "                                           text)\n",
    "            make_matching_figure(rgb_img1, rgb_img2, abs_m0, abs_m1, color, abs_m0, abs_m1, text,\n",
    "                                 path=\"magsacpp\"+str(conf['residual_threshold']) +\"_rmse_\"+str(rmse)+\"_inliers_\" + str(n_inliers) +\".pdf\")\n",
    "    return conf\n",
    "\n",
    "\n",
    "def predict_and_print(ph,rgb_img1, rgb_img2, matcher, img0_raw, img1_raw, points, points_patch,points_patch_ref,\n",
    "                      searching_window_w, searching_window_h, patch_w, patch_h, configs_ransac ,threshold_inliers,random_select =False):\n",
    "    '''\n",
    "        This code performs an image matching task with the given matcher, which takes two raw images and outputs corresponding features. The code first resizes the two raw images to (640, 480) and converts them to torch tensors, normalizing them by dividing each pixel by 255. The two images are then passed to the matcher to get feature matches and confidence scores.\n",
    "        The code then computes two weighted average points based on the matches, one weighted by the confidence score and the other by a uniform weight. If the number of matches is greater than 0, the code returns the weighted average points and prints them as figures if verbose is set to True. The output figures are saved as \"LoFTR-colab-demo.pdf\".\n",
    "I       f there are no matches, the code returns None, None, None, None.\n",
    "'''\n",
    "\n",
    "    img0 = torch.from_numpy(img0_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "    img1 = torch.from_numpy(img1_raw)[None][None].cuda().to(torch.float) / 255.\n",
    "\n",
    "    batch = {'image0': img0, 'image1': img1}\n",
    "\n",
    "    # Inference with LoFTR and get prediction\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.reset_peak_memory_stats(device=\"cuda\")\n",
    "        matcher.matcher(batch)\n",
    "        print(\"max memory allocated cuda\", torch.cuda.max_memory_allocated(device=\"cuda\"))\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "\n",
    "    if mkpts0.shape[0] > 0:\n",
    "        return [postproces_and_metric(conf, mkpts0, mkpts1, img0, ph, points, points_patch,points_patch_ref,\n",
    "                                           searching_window_w, searching_window_h, patch_w, patch_h, rgb_img1, rgb_img2,\n",
    "                                           mconf, threshold_inliers,random_select) for conf in configs_ransac]\n",
    "\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "\n",
    "loaddirec = \"model.pth\"\n",
    "save_path = \"./\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "'''\n",
    " It takes two images as input, performs image denoising, and then uses a matcher to find the similarity between a patch from the first image and the second image.\n",
    "\n",
    "The code uses a loop to run the processing for 50 times, for each iteration:\n",
    "\n",
    "It calls the function get_sample to get the images, points, and datasets.\n",
    "It denoises the raw images using 3 denoising methods (mean, bilateral, and lee_enhanced). If the denoising didn't produce a result, the code skips to the next iteration.\n",
    "The code calls the function predict_and_print to get the result of the matcher and to find the similarity between the patch and the search window.\n",
    "The code uses the result of the matcher to calculate the error in meters between the predicted position and the real position.\n",
    "The code draws circles on the original full map to show the predicted and real positions.\n",
    "The code displays the original full map if verbose is set to True.\n",
    "The code accumulates the error for each iteration and prints the final result, which includes the number of successful predictions and the mean error in meters.\n",
    "'''\n",
    "\n",
    "\n",
    "def lee_filter(img, size):\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img ** 2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean ** 2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output\n",
    "\n",
    "\n",
    "def do_test(matcher_in, ph, size_search=(640, 480), size_patch=(int(180 * 1.333333), int(180)),threshold_inliers=5,\n",
    "            configs_ransac=None, verbose=True,random_select=False):\n",
    "\n",
    "    patch_dest,search_window_source, rgb_img1, rgb_img2, points, points_patch_ref, points_patch = get_sample(ph,\n",
    "                                                                                                size_search, size_patch,\n",
    "                                                                                                verbose=verbose)\n",
    "    if rgb_img1 is None:\n",
    "        return None\n",
    "\n",
    "    import skimage.measure\n",
    "\n",
    "    results = predict_and_print(ph,rgb_img1, rgb_img2, matcher_in, search_window_source, patch_dest, points, points_patch,points_patch_ref,\n",
    "                                 size_search[0], size_search[1], size_patch[0], size_patch[1]\n",
    "                                , configs_ransac,threshold_inliers,random_select\n",
    "                               )\n",
    "\n",
    "    entropy = skimage.measure.shannon_entropy(patch_dest)\n",
    "\n",
    "    return results, entropy\n",
    "\n",
    "\n",
    "def get_list():\n",
    "    path_of_the_directory = './data/UAVSAR/'\n",
    "    paths = []\n",
    "    for filename in os.listdir(path_of_the_directory):\n",
    "        f = os.path.join(path_of_the_directory, filename)\n",
    "        if len(os.listdir(f)) > 3:\n",
    "            if not os.path.isfile(f):\n",
    "                lst = sorted([os.path.abspath(os.path.join(f, p)) for p in os.listdir(f)])\n",
    "                lst = [item for item in lst if \"az_rg\" not in item]\n",
    "                paths.append(lst)\n",
    "\n",
    "    return paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 12:07:47.084 | INFO     | model.lightning_loftr:__init__:34 - Load './weights/outdoor-lite-SEA.ckpt' as pretrained checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(656, 2) (15, 2)\n",
      "Magsac Execution time: 0.002278566360473633 seconds inliers: 5\n",
      "Magsac Execution time: 0.002417325973510742 seconds inliers: 8\n",
      "Magsac Execution time: 0.0022432804107666016 seconds inliers: 18\n",
      "(656, 2) (15, 2)\n",
      "Magsac Execution time: 0.002246379852294922 seconds inliers: 67\n",
      "(656, 2) (15, 2)\n",
      "Magsac Execution time: 0.0023937225341796875 seconds inliers: 102\n",
      "(656, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 6.324555320336759, 'inliers': 656}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 11.59885051775965, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 32.862339133624275, 'inliers': 67}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 33.11897743993112, 'inliers': 102}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.0020356178283691406 seconds inliers: 4\n",
      "Magsac Execution time: 0.0023162364959716797 seconds inliers: 8\n",
      "Magsac Execution time: 0.0022106170654296875 seconds inliers: 15\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.002369403839111328 seconds inliers: 40\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.002448558807373047 seconds inliers: 77\n",
      "(693, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 122.53978945632312, 'inliers': 693}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 25.15949125081825, 'inliers': 15}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 15.386140950002158, 'inliers': 40}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 9.029581016488713, 'inliers': 77}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(609, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014913082122802734 seconds inliers: 5\n",
      "Magsac Execution time: 0.0021164417266845703 seconds inliers: 8\n",
      "Magsac Execution time: 0.0013113021850585938 seconds inliers: 16\n",
      "(609, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014722347259521484 seconds inliers: 37\n",
      "(609, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014202594757080078 seconds inliers: 64\n",
      "(609, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 1.0, 'inliers': 609}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 19.9916649298318, 'inliers': 16}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 23.923489154664153, 'inliers': 37}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 22.417255258691537, 'inliers': 64}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(596, 2) (15, 2)\n",
      "Magsac Execution time: 0.001312255859375 seconds inliers: 4\n",
      "Magsac Execution time: 0.002038240432739258 seconds inliers: 5\n",
      "Magsac Execution time: 0.001249074935913086 seconds inliers: 6\n",
      "Magsac Execution time: 0.001300811767578125 seconds inliers: 8\n",
      "Magsac Execution time: 0.0013058185577392578 seconds inliers: 11\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 204.70710783946902, 'inliers': 596}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(650, 2) (15, 2)\n",
      "Magsac Execution time: 0.0013773441314697266 seconds inliers: 5\n",
      "Magsac Execution time: 0.0015518665313720703 seconds inliers: 5\n",
      "Magsac Execution time: 0.0014104843139648438 seconds inliers: 6\n",
      "Magsac Execution time: 0.0014872550964355469 seconds inliers: 7\n",
      "Magsac Execution time: 0.0014543533325195312 seconds inliers: 8\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 67.42403132415029, 'inliers': 650}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(617, 2) (15, 2)\n",
      "Magsac Execution time: 0.0017113685607910156 seconds inliers: 4\n",
      "Magsac Execution time: 0.001783609390258789 seconds inliers: 11\n",
      "Magsac Execution time: 0.0014297962188720703 seconds inliers: 13\n",
      "Magsac Execution time: 0.0014584064483642578 seconds inliers: 16\n",
      "(617, 2) (15, 2)\n",
      "Magsac Execution time: 0.0015590190887451172 seconds inliers: 31\n",
      "(617, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 65.0, 'inliers': 617}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 83.36945883635485, 'inliers': 16}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 83.81288683728773, 'inliers': 31}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(730, 2) (15, 2)\n",
      "Magsac Execution time: 0.002496957778930664 seconds inliers: 8\n",
      "Magsac Execution time: 0.002871990203857422 seconds inliers: 22\n",
      "(730, 2) (15, 2)\n",
      "Magsac Execution time: 0.0024747848510742188 seconds inliers: 67\n",
      "(730, 2) (15, 2)\n",
      "Magsac Execution time: 0.002676725387573242 seconds inliers: 138\n",
      "(730, 2) (15, 2)\n",
      "Magsac Execution time: 0.0030164718627929688 seconds inliers: 230\n",
      "(730, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 137.2953021774598, 'inliers': 730}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': 5.440588203494177, 'inliers': 22}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 5.11207720338155, 'inliers': 67}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 6.005552985917839, 'inliers': 138}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 6.356099432828281, 'inliers': 230}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(561, 2) (15, 2)\n",
      "Magsac Execution time: 0.001241445541381836 seconds inliers: 0\n",
      "Magsac Execution time: 0.0016431808471679688 seconds inliers: 5\n",
      "Magsac Execution time: 0.001184701919555664 seconds inliers: 5\n",
      "Magsac Execution time: 0.0011911392211914062 seconds inliers: 5\n",
      "Magsac Execution time: 0.0012316703796386719 seconds inliers: 12\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 122.10241602851272, 'inliers': 561}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 12}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(642, 2) (15, 2)\n",
      "Magsac Execution time: 0.001962900161743164 seconds inliers: 4\n",
      "Magsac Execution time: 0.002201080322265625 seconds inliers: 7\n",
      "Magsac Execution time: 0.002295970916748047 seconds inliers: 13\n",
      "Magsac Execution time: 0.002246379852294922 seconds inliers: 23\n",
      "(642, 2) (15, 2)\n",
      "Magsac Execution time: 0.002936840057373047 seconds inliers: 45\n",
      "(642, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 147.52626884728022, 'inliers': 642}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 53.387888763901, 'inliers': 23}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 53.99876541798587, 'inliers': 45}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(622, 2) (15, 2)\n",
      "Magsac Execution time: 0.0015439987182617188 seconds inliers: 5\n",
      "Magsac Execution time: 0.001958131790161133 seconds inliers: 5\n",
      "Magsac Execution time: 0.0014188289642333984 seconds inliers: 5\n",
      "Magsac Execution time: 0.0014503002166748047 seconds inliers: 6\n",
      "Magsac Execution time: 0.0014345645904541016 seconds inliers: 15\n",
      "(622, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 61.66036003787198, 'inliers': 622}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 91.88652422054788, 'inliers': 15}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(625, 2) (15, 2)\n",
      "Magsac Execution time: 0.0016269683837890625 seconds inliers: 4\n",
      "Magsac Execution time: 0.0018892288208007812 seconds inliers: 5\n",
      "Magsac Execution time: 0.0017015933990478516 seconds inliers: 6\n",
      "Magsac Execution time: 0.0016934871673583984 seconds inliers: 10\n",
      "Magsac Execution time: 0.0017571449279785156 seconds inliers: 14\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 165.92166826548, 'inliers': 625}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 10}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 14}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(679, 2) (15, 2)\n",
      "Magsac Execution time: 0.0019655227661132812 seconds inliers: 5\n",
      "Magsac Execution time: 0.0022830963134765625 seconds inliers: 7\n",
      "Magsac Execution time: 0.0021190643310546875 seconds inliers: 15\n",
      "(679, 2) (15, 2)\n",
      "Magsac Execution time: 0.002504587173461914 seconds inliers: 30\n",
      "(679, 2) (15, 2)\n",
      "Magsac Execution time: 0.002544879913330078 seconds inliers: 47\n",
      "(679, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 59.93329625508679, 'inliers': 679}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 9.640193635676274, 'inliers': 15}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 22.494443758403985, 'inliers': 30}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 26.252618916976648, 'inliers': 47}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(706, 2) (15, 2)\n",
      "Magsac Execution time: 0.0020956993103027344 seconds inliers: 5\n",
      "Magsac Execution time: 0.002337217330932617 seconds inliers: 7\n",
      "Magsac Execution time: 0.00212860107421875 seconds inliers: 13\n",
      "Magsac Execution time: 0.0021309852600097656 seconds inliers: 28\n",
      "(706, 2) (15, 2)\n",
      "Magsac Execution time: 0.0023725032806396484 seconds inliers: 72\n",
      "(706, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 83.2586331859946, 'inliers': 706}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 77.91063256492446, 'inliers': 28}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 15.908069231263317, 'inliers': 72}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(628, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014753341674804688 seconds inliers: 5\n",
      "Magsac Execution time: 0.001600027084350586 seconds inliers: 6\n",
      "Magsac Execution time: 0.0015442371368408203 seconds inliers: 6\n",
      "Magsac Execution time: 0.0015566349029541016 seconds inliers: 7\n",
      "Magsac Execution time: 0.0017735958099365234 seconds inliers: 11\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 82.41965784932621, 'inliers': 628}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(697, 2) (15, 2)\n",
      "Magsac Execution time: 0.0018491744995117188 seconds inliers: 6\n",
      "Magsac Execution time: 0.002004861831665039 seconds inliers: 19\n",
      "(697, 2) (15, 2)\n",
      "Magsac Execution time: 0.0017120838165283203 seconds inliers: 50\n",
      "(697, 2) (15, 2)\n",
      "Magsac Execution time: 0.0017783641815185547 seconds inliers: 93\n",
      "(697, 2) (15, 2)\n",
      "Magsac Execution time: 0.0018222332000732422 seconds inliers: 167\n",
      "(697, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 302.03476621077914, 'inliers': 697}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': 6.180614856144977, 'inliers': 19}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 7.211102550927978, 'inliers': 50}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 7.443117626371358, 'inliers': 93}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 6.439461675223067, 'inliers': 167}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.0025861263275146484 seconds inliers: 5\n",
      "Magsac Execution time: 0.0027904510498046875 seconds inliers: 15\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.0025904178619384766 seconds inliers: 36\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.002493619918823242 seconds inliers: 81\n",
      "(693, 2) (15, 2)\n",
      "Magsac Execution time: 0.0025701522827148438 seconds inliers: 152\n",
      "(693, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 12.649110640673518, 'inliers': 693}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': 7.741662181555931, 'inliers': 15}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 7.878240074195928, 'inliers': 36}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 8.402380615040002, 'inliers': 81}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 8.140434058861153, 'inliers': 152}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(573, 2) (15, 2)\n",
      "Magsac Execution time: 0.0012848377227783203 seconds inliers: 0\n",
      "Magsac Execution time: 0.001590728759765625 seconds inliers: 5\n",
      "Magsac Execution time: 0.0012485980987548828 seconds inliers: 5\n",
      "Magsac Execution time: 0.0012383460998535156 seconds inliers: 5\n",
      "Magsac Execution time: 0.001268625259399414 seconds inliers: 5\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 349.51537877466853, 'inliers': 573}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(606, 2) (15, 2)\n",
      "Magsac Execution time: 0.0012841224670410156 seconds inliers: 0\n",
      "Magsac Execution time: 0.0014536380767822266 seconds inliers: 5\n",
      "Magsac Execution time: 0.0012297630310058594 seconds inliers: 5\n",
      "Magsac Execution time: 0.0012357234954833984 seconds inliers: 4\n",
      "Magsac Execution time: 0.00130462646484375 seconds inliers: 7\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 24.758836806279895, 'inliers': 606}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(647, 2) (15, 2)\n",
      "Magsac Execution time: 0.0017096996307373047 seconds inliers: 4\n",
      "Magsac Execution time: 0.0020029544830322266 seconds inliers: 6\n",
      "Magsac Execution time: 0.0016148090362548828 seconds inliers: 11\n",
      "Magsac Execution time: 0.0017282962799072266 seconds inliers: 23\n",
      "(647, 2) (15, 2)\n",
      "Magsac Execution time: 0.001962900161743164 seconds inliers: 31\n",
      "(647, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 228.23890991677996, 'inliers': 647}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 19.174636024359543, 'inliers': 23}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 27.747672575070748, 'inliers': 31}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(577, 2) (15, 2)\n",
      "Magsac Execution time: 0.001253366470336914 seconds inliers: 0\n",
      "Magsac Execution time: 0.0014853477478027344 seconds inliers: 5\n",
      "Magsac Execution time: 0.0011954307556152344 seconds inliers: 5\n",
      "Magsac Execution time: 0.0011892318725585938 seconds inliers: 6\n",
      "Magsac Execution time: 0.00128173828125 seconds inliers: 7\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 252.57870060636546, 'inliers': 577}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(682, 2) (15, 2)\n",
      "Magsac Execution time: 0.0022919178009033203 seconds inliers: 6\n",
      "Magsac Execution time: 0.0024907588958740234 seconds inliers: 9\n",
      "Magsac Execution time: 0.002272367477416992 seconds inliers: 20\n",
      "(682, 2) (15, 2)\n",
      "Magsac Execution time: 0.002552032470703125 seconds inliers: 47\n",
      "(682, 2) (15, 2)\n",
      "Magsac Execution time: 0.0026476383209228516 seconds inliers: 77\n",
      "(682, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 26.248809496813376, 'inliers': 682}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 9}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 8.839306156782518, 'inliers': 20}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 8.694826047713663, 'inliers': 47}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 8.752142594816426, 'inliers': 77}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(644, 2) (15, 2)\n",
      "Magsac Execution time: 0.0016379356384277344 seconds inliers: 4\n",
      "Magsac Execution time: 0.0017392635345458984 seconds inliers: 5\n",
      "Magsac Execution time: 0.0015451908111572266 seconds inliers: 6\n",
      "Magsac Execution time: 0.0017087459564208984 seconds inliers: 8\n",
      "Magsac Execution time: 0.0017457008361816406 seconds inliers: 10\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 304.38462510448846, 'inliers': 644}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 4}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 10}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(650, 2) (15, 2)\n",
      "Magsac Execution time: 0.0015177726745605469 seconds inliers: 5\n",
      "Magsac Execution time: 0.0020580291748046875 seconds inliers: 6\n",
      "Magsac Execution time: 0.001504659652709961 seconds inliers: 8\n",
      "Magsac Execution time: 0.0016109943389892578 seconds inliers: 11\n",
      "Magsac Execution time: 0.0014209747314453125 seconds inliers: 23\n",
      "(650, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 150.2131818450032, 'inliers': 650}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 162.84634884864116, 'inliers': 23}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(758, 2) (15, 2)\n",
      "Magsac Execution time: 0.0028595924377441406 seconds inliers: 8\n",
      "Magsac Execution time: 0.0033850669860839844 seconds inliers: 15\n",
      "(758, 2) (15, 2)\n",
      "Magsac Execution time: 0.005424022674560547 seconds inliers: 42\n",
      "(758, 2) (15, 2)\n",
      "Magsac Execution time: 0.005992412567138672 seconds inliers: 132\n",
      "(758, 2) (15, 2)\n",
      "Magsac Execution time: 0.006478786468505859 seconds inliers: 254\n",
      "(758, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 102.30347012687302, 'inliers': 758}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': 22.550683655564267, 'inliers': 15}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': 5.118593556827891, 'inliers': 42}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 6.587867636800241, 'inliers': 132}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 7.831560082980487, 'inliers': 254}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(643, 2) (15, 2)\n",
      "Magsac Execution time: 0.001760244369506836 seconds inliers: 5\n",
      "Magsac Execution time: 0.001994609832763672 seconds inliers: 6\n",
      "Magsac Execution time: 0.0017712116241455078 seconds inliers: 12\n",
      "Magsac Execution time: 0.0017993450164794922 seconds inliers: 20\n",
      "(643, 2) (15, 2)\n",
      "Magsac Execution time: 0.002012014389038086 seconds inliers: 31\n",
      "(643, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 216.8363438171747, 'inliers': 643}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 12}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 5.507570547286102, 'inliers': 20}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 5.458937625582473, 'inliers': 31}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(586, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014488697052001953 seconds inliers: 5\n",
      "Magsac Execution time: 0.001928091049194336 seconds inliers: 5\n",
      "Magsac Execution time: 0.0013370513916015625 seconds inliers: 7\n",
      "Magsac Execution time: 0.0013544559478759766 seconds inliers: 10\n",
      "Magsac Execution time: 0.0014362335205078125 seconds inliers: 13\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 24.08318915758459, 'inliers': 586}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 10}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(437, 2) (15, 2)\n",
      "Magsac Execution time: 0.0010135173797607422 seconds inliers: 0\n",
      "Magsac Execution time: 0.0012707710266113281 seconds inliers: 0\n",
      "Magsac Execution time: 0.0008752346038818359 seconds inliers: 0\n",
      "Magsac Execution time: 0.0008871555328369141 seconds inliers: 5\n",
      "Magsac Execution time: 0.0009133815765380859 seconds inliers: 7\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 208.54016399725018, 'inliers': 437}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(581, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014524459838867188 seconds inliers: 5\n",
      "Magsac Execution time: 0.0019419193267822266 seconds inliers: 5\n",
      "Magsac Execution time: 0.0014216899871826172 seconds inliers: 6\n",
      "Magsac Execution time: 0.0016243457794189453 seconds inliers: 6\n",
      "Magsac Execution time: 0.0016508102416992188 seconds inliers: 11\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 263.80485211610494, 'inliers': 581}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(528, 2) (15, 2)\n",
      "Magsac Execution time: 0.0012314319610595703 seconds inliers: 0\n",
      "Magsac Execution time: 0.0013637542724609375 seconds inliers: 0\n",
      "Magsac Execution time: 0.0012025833129882812 seconds inliers: 6\n",
      "Magsac Execution time: 0.0011894702911376953 seconds inliers: 11\n",
      "Magsac Execution time: 0.0013513565063476562 seconds inliers: 14\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 128.81770064707723, 'inliers': 528}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 14}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(598, 2) (15, 2)\n",
      "Magsac Execution time: 0.0013887882232666016 seconds inliers: 0\n",
      "Magsac Execution time: 0.0016314983367919922 seconds inliers: 7\n",
      "Magsac Execution time: 0.001397848129272461 seconds inliers: 12\n",
      "Magsac Execution time: 0.001428842544555664 seconds inliers: 21\n",
      "(598, 2) (15, 2)\n",
      "Magsac Execution time: 0.001581430435180664 seconds inliers: 27\n",
      "(598, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 180.27756377319946, 'inliers': 598}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 7}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 12}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 112.43872405299994, 'inliers': 21}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 122.65833305025251, 'inliers': 27}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(670, 2) (15, 2)\n",
      "Magsac Execution time: 0.0018396377563476562 seconds inliers: 5\n",
      "Magsac Execution time: 0.0020780563354492188 seconds inliers: 6\n",
      "Magsac Execution time: 0.0017852783203125 seconds inliers: 10\n",
      "Magsac Execution time: 0.0018813610076904297 seconds inliers: 23\n",
      "(670, 2) (15, 2)\n",
      "Magsac Execution time: 0.0019114017486572266 seconds inliers: 32\n",
      "(670, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 55.14526271584895, 'inliers': 670}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 10}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 58.9406481131655, 'inliers': 23}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 77.80831146692063, 'inliers': 32}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(40, 2) (15, 2)\n",
      "Magsac Execution time: 0.00015544891357421875 seconds inliers: 0\n",
      "Magsac Execution time: 0.0003921985626220703 seconds inliers: 0\n",
      "Magsac Execution time: 0.00013399124145507812 seconds inliers: 0\n",
      "Magsac Execution time: 0.00010848045349121094 seconds inliers: 0\n",
      "Magsac Execution time: 0.00010538101196289062 seconds inliers: 0\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 156.11534197509224, 'inliers': 40}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(600, 2) (15, 2)\n",
      "Magsac Execution time: 0.0012760162353515625 seconds inliers: 5\n",
      "Magsac Execution time: 0.0015058517456054688 seconds inliers: 5\n",
      "Magsac Execution time: 0.001209259033203125 seconds inliers: 10\n",
      "Magsac Execution time: 0.0012586116790771484 seconds inliers: 18\n",
      "(600, 2) (15, 2)\n",
      "Magsac Execution time: 0.0014488697052001953 seconds inliers: 27\n",
      "(600, 2) (15, 2)\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 58.463663928973865, 'inliers': 600}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 10}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': 191.04414847533715, 'inliers': 18}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': 173.2943545916408, 'inliers': 27}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(611, 2) (15, 2)\n",
      "Magsac Execution time: 0.0015077590942382812 seconds inliers: 3\n",
      "Magsac Execution time: 0.0018508434295654297 seconds inliers: 5\n",
      "Magsac Execution time: 0.0018019676208496094 seconds inliers: 6\n",
      "Magsac Execution time: 0.0017232894897460938 seconds inliers: 8\n",
      "Magsac Execution time: 0.0017688274383544922 seconds inliers: 11\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 382.29438918194967, 'inliers': 611}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 3}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 8}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 11}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(545, 2) (15, 2)\n",
      "Magsac Execution time: 0.001435995101928711 seconds inliers: 5\n",
      "Magsac Execution time: 0.002067089080810547 seconds inliers: 5\n",
      "Magsac Execution time: 0.0013394355773925781 seconds inliers: 6\n",
      "Magsac Execution time: 0.0013854503631591797 seconds inliers: 9\n",
      "Magsac Execution time: 0.0014727115631103516 seconds inliers: 13\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 35.4682957019364, 'inliers': 545}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 5}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 9}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 13}\n",
      "torch.Size([1, 1, 400, 400]) torch.Size([1, 1, 400, 400])\n",
      "max memory allocated cuda 443707392\n",
      "(670, 2) (15, 2)\n",
      "Magsac Execution time: 0.0015397071838378906 seconds inliers: 0\n",
      "Magsac Execution time: 0.002174854278564453 seconds inliers: 0\n",
      "Magsac Execution time: 0.001375436782836914 seconds inliers: 0\n",
      "Magsac Execution time: 0.0014188289642333984 seconds inliers: 6\n",
      "Magsac Execution time: 0.0014743804931640625 seconds inliers: 12\n",
      "{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0, 'rmse': 205.05608988762074, 'inliers': 670}\n",
      "{'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100, 'rmse': -1, 'inliers': 0}\n",
      "{'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100, 'rmse': -1, 'inliers': 6}\n",
      "{'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100, 'rmse': -1, 'inliers': 12}\n",
      "   min_samples  residual_threshold  max_trials        rmse     inliers  \\\n",
      "0            0                -1.0           0  138.748381  612.500000   \n",
      "1            4                 0.5         100    0.000000    0.000000   \n",
      "2            4                 1.0         100   10.478387   17.750000   \n",
      "3            4                 1.5         100   11.172169   31.000000   \n",
      "4            4                 2.0         100   43.151404   49.235294   \n",
      "5            4                 2.5         100   49.671491   79.157895   \n",
      "\n",
      "   Accepted_match  total_match  \n",
      "0              36           36  \n",
      "1               0           36  \n",
      "2               4           36  \n",
      "3               9           36  \n",
      "4              17           36  \n",
      "5              19           36  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "matcher_in = get_matcher(\"outdoor\", unlock=True)\n",
    "verbose = False\n",
    "random.seed(9)\n",
    "count_yes = 0\n",
    "test_for_each_pair = 1\n",
    "configs_ransac = [{'min_samples': 0, 'residual_threshold': -1, 'max_trials': 0},\n",
    "            {'min_samples': 4, 'residual_threshold': 0.5, 'max_trials': 100},\n",
    "\n",
    "                {'min_samples': 4, 'residual_threshold': 1, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 1.5, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 2, 'max_trials': 100},\n",
    "                  {'min_samples': 4, 'residual_threshold': 2.5, 'max_trials': 100},]\n",
    "\n",
    "paths = get_list()\n",
    "\n",
    "metrics = [{'rmse': 0, 'inliers': 0, 'accepted_match': 0} for conf in range(len(configs_ransac))]\n",
    "\n",
    "for ph in paths:\n",
    "    for x in range(test_for_each_pair):\n",
    "\n",
    "\n",
    "        results, entropy = do_test(matcher_in, ph, size_search=(400, 400),\n",
    "                                                     size_patch=(240, 240),\n",
    "                                                     verbose=verbose,\n",
    "                                                     configs_ransac=configs_ransac,threshold_inliers=15,random_select=False)\n",
    "\n",
    "\n",
    "        if results is not None:\n",
    "\n",
    "            for i in range(len(results)):\n",
    "                if results[i]['rmse'] >= 0:\n",
    "\n",
    "\n",
    "                    metrics[i]['rmse'] += results[i]['rmse']\n",
    "                    metrics[i]['inliers'] += results[i]['inliers']\n",
    "                    metrics[i]['accepted_match'] += 1\n",
    "                print(results[i])\n",
    "                #print(metrics[i])\n",
    "\n",
    "            count_yes += 1\n",
    "\n",
    "data = []\n",
    "for i in range(len(metrics)):\n",
    "    if metrics[i]['accepted_match'] > 0:\n",
    "        metrics[i]['rmse'] /= metrics[i]['accepted_match']\n",
    "        metrics[i]['inliers'] /= metrics[i]['accepted_match']\n",
    "\n",
    "    configs_ransac[i]['rmse'] = metrics[i]['rmse']\n",
    "    configs_ransac[i]['inliers'] = metrics[i]['inliers']\n",
    "    configs_ransac[i]['Accepted_match'] = metrics[i]['accepted_match']\n",
    "    configs_ransac[i]['total_match'] = test_for_each_pair * len(paths)\n",
    "    data.append(configs_ransac[i])\n",
    "    #print(\"Configuration:\",configs_ransac[i-1],\" Metrics:\",metrics[i], \" Accepted_match:\", metrics[i]['accepted_match'] ,\"/\", test_for_each_pair*len(paths))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel('players.xlsx')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   min_samples  residual_threshold  max_trials        rmse     inliers  \\\n",
      "0            0                -1.0           0  138.748381  612.500000   \n",
      "1            4                 0.5         100    0.000000    0.000000   \n",
      "2            4                 1.0         100   10.478387   17.750000   \n",
      "3            4                 1.5         100   11.172169   31.000000   \n",
      "4            4                 2.0         100   43.151404   49.235294   \n",
      "5            4                 2.5         100   49.671491   79.157895   \n",
      "\n",
      "   Accepted_match  total_match  \n",
      "0              36           36  \n",
      "1               0           36  \n",
      "2               4           36  \n",
      "3               9           36  \n",
      "4              17           36  \n",
      "5              19           36  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_excel('players.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
