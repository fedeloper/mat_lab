{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;35mYour model contains \"Tile\" ops or/and \"ConstantOfShape\" ops. Folding these ops \u001B[0m\r\n",
      "\u001B[1;35mcan make the simplified model much larger. If it is not expected, please specify\u001B[0m\r\n",
      "\u001B[1;35m\"--no-large-tensor\" (which will lose some optimization chances)\u001B[0m\r\n",
      "Simplifying\u001B[33m...\u001B[0m\r\n",
      "Finish! Here is the difference:\r\n",
      "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃\u001B[1m \u001B[0m\u001B[1m               \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOriginal Model\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mSimplified Model\u001B[0m\u001B[1m \u001B[0m┃\r\n",
      "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\r\n",
      "│ Add             │ 96             │ 96               │\r\n",
      "│ ArgMax          │ 1              │ 1                │\r\n",
      "│ Cast            │ 87             │ \u001B[1;32m30              \u001B[0m │\r\n",
      "│ Concat          │ 60             │ \u001B[1;32m56              \u001B[0m │\r\n",
      "│ Constant        │ 727            │ \u001B[1;32m335             \u001B[0m │\r\n",
      "│ ConstantOfShape │ 29             │ \u001B[1;32m1               \u001B[0m │\r\n",
      "│ Conv            │ 54             │ 54               │\r\n",
      "│ Div             │ 55             │ 55               │\r\n",
      "│ Einsum          │ 8              │ 8                │\r\n",
      "│ Elu             │ 4              │ 4                │\r\n",
      "│ Equal           │ 37             │ \u001B[1;32m14              \u001B[0m │\r\n",
      "│ Erf             │ 35             │ 35               │\r\n",
      "│ Expand          │ 38             │ 38               │\r\n",
      "│ Flatten         │ 4              │ 4                │\r\n",
      "│ Gather          │ 88             │ \u001B[1;32m86              \u001B[0m │\r\n",
      "│ GatherND        │ 4              │ 4                │\r\n",
      "│ Greater         │ 1              │ 1                │\r\n",
      "│ Identity        │ 2              │ 2                │\r\n",
      "│ If              │ 3              │ 3                │\r\n",
      "│ MatMul          │ 12             │ 12               │\r\n",
      "│ Mod             │ 2              │ 2                │\r\n",
      "│ Mul             │ 126            │ \u001B[1;32m98              \u001B[0m │\r\n",
      "│ NonZero         │ 5              │ \u001B[1;32m2               \u001B[0m │\r\n",
      "│ Not             │ 6              │ \u001B[1;32m3               \u001B[0m │\r\n",
      "│ Pad             │ 2              │ 2                │\r\n",
      "│ Pow             │ 6              │ 6                │\r\n",
      "│ Range           │ 34             │ 34               │\r\n",
      "│ Reciprocal      │ 2              │ 2                │\r\n",
      "│ ReduceMax       │ 3              │ 3                │\r\n",
      "│ ReduceMean      │ 8              │ 8                │\r\n",
      "│ ReduceSum       │ 4              │ 4                │\r\n",
      "│ Relu            │ 3              │ 3                │\r\n",
      "│ Reshape         │ 65             │ \u001B[1;32m63              \u001B[0m │\r\n",
      "│ Resize          │ 9              │ 9                │\r\n",
      "│ ScatterND       │ 8              │ 8                │\r\n",
      "│ SequenceAt      │ 4              │ 4                │\r\n",
      "│ Shape           │ 121            │ \u001B[1;32m60              \u001B[0m │\r\n",
      "│ Slice           │ 30             │ 30               │\r\n",
      "│ Softmax         │ 3              │ 3                │\r\n",
      "│ Split           │ 1              │ 1                │\r\n",
      "│ SplitToSequence │ 2              │ 2                │\r\n",
      "│ Sqrt            │ 5              │ 5                │\r\n",
      "│ Squeeze         │ 3              │ 3                │\r\n",
      "│ Sub             │ 16             │ \u001B[1;32m12              \u001B[0m │\r\n",
      "│ Transpose       │ 12             │ \u001B[1;32m9               \u001B[0m │\r\n",
      "│ Unsqueeze       │ 108            │ \u001B[1;32m103             \u001B[0m │\r\n",
      "│ Where           │ 29             │ \u001B[1;32m9               \u001B[0m │\r\n",
      "│ Model Size      │ 71.2MiB        │ \u001B[1;32m28.0MiB         \u001B[0m │\r\n",
      "└─────────────────┴────────────────┴──────────────────┘\r\n"
     ]
    }
   ],
   "source": [
    "!onnxsim model.onnx model_simplified.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Onnxruntimes all optmizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from model_simplified_optimized.onnx failed:Load model model_simplified_optimized.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNoSuchFile\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# To enable model serialization after graph optimization set this\u001B[39;00m\n\u001B[1;32m      9\u001B[0m sess_options\u001B[38;5;241m.\u001B[39moptimized_model_filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_simplified_optimized_optimized.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 11\u001B[0m session \u001B[38;5;241m=\u001B[39m \u001B[43mort\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInferenceSession\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_simplified_optimized.onnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msess_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:360\u001B[0m, in \u001B[0;36mInferenceSession.__init__\u001B[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001B[0m\n\u001B[1;32m    357\u001B[0m disabled_optimizers \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisabled_optimizers\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisabled_optimizers\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 360\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_inference_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproviders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprovider_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisabled_optimizers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "File \u001B[0;32m~/anaconda3/envs/pythonProject/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:397\u001B[0m, in \u001B[0;36mInferenceSession._create_inference_session\u001B[0;34m(self, providers, provider_options, disabled_optimizers)\u001B[0m\n\u001B[1;32m    395\u001B[0m session_options \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sess_options \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sess_options \u001B[38;5;28;01melse\u001B[39;00m C\u001B[38;5;241m.\u001B[39mget_default_session_options()\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_path:\n\u001B[0;32m--> 397\u001B[0m     sess \u001B[38;5;241m=\u001B[39m \u001B[43mC\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInferenceSession\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_config_from_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    399\u001B[0m     sess \u001B[38;5;241m=\u001B[39m C\u001B[38;5;241m.\u001B[39mInferenceSession(session_options, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_bytes, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_config_from_model)\n",
      "\u001B[0;31mNoSuchFile\u001B[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from model_simplified_optimized.onnx failed:Load model model_simplified_optimized.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "sess_options = ort.SessionOptions()\n",
    "\n",
    "# Set graph optimization level\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "# To enable model serialization after graph optimization set this\n",
    "sess_options.optimized_model_filepath = \"model_simplified_optimized_optimized.onnx\"\n",
    "\n",
    "session = ort.InferenceSession(\"model_simplified_optimized.onnx\", sess_options)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quantized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize, quantize_dynamic, QuantType, QuantFormat, quantize_static, QuantizationMode\n",
    "\n",
    "quantized_model = quantize_dynamic(\"model_simplified_optimized.onnx\",\"model_QQ.onnx\",weight_type=QuantType.QUInt8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "import time\n",
    "def test_time(path,inputs):\n",
    "\n",
    "    providers = [(\"CPUExecutionProvider\")]\n",
    "    sess_options = ort.SessionOptions()\n",
    "    sess = ort.InferenceSession(path, sess_options=sess_options, providers=providers)\n",
    "    t0 = time.time()\n",
    "    for x in range(3):\n",
    "      outputs2 = sess.run(None,inputs )\n",
    "    t1 = time.time()\n",
    "    print(\"total time 1 inference on CPU: \",path,(t1-t0)/3)\n",
    "\n",
    "    return outputs2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dummy_image = torch.randn(1, 1, 800,720, device=\"cpu\").numpy()\n",
    "inputs= {'image0': dummy_image,'image1': dummy_image}\n",
    "\n",
    "o2= test_time(\"model.onnx\",inputs)\n",
    "o1= test_time(\"model_simplified_optimized.onnx\",inputs)\n",
    "o3= test_time(\"model_optimized.onnx\",inputs)\n",
    "o4= test_time(\"model_quantized.onnx\",inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
